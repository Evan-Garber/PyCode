{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0be27fed-3f0c-4f1f-92cc-243edc08fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4278eb84-c47c-4456-8500-c8231863981c",
   "metadata": {},
   "source": [
    "## Using normal autodifferentiation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7671d92c-96bd-4981-9324-05247970d7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "U:    tensor([[ 0.6070+0.1734j,  0.5411+0.5555j],\n",
      "        [-0.5613+0.5351j,  0.6131-0.1508j]], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Loss: (1.2499594354453016+0.032396773404116j)\n",
      "\n",
      "U:    tensor([[ 0.7040-0.0059j, -0.6919-0.1599j],\n",
      "        [ 0.7101+0.0059j,  0.6833+0.1699j]], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Loss: (8.761761998399287e-05-5.304814132425017e-06j)\n",
      "\n",
      "U:    tensor([[ 0.7071+1.5332e-07j, -0.6875-1.6531e-01j],\n",
      "        [ 0.7071-1.5506e-07j,  0.6875+1.6531e-01j]], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Loss: (1.1368683772161603e-13-2.4665192218120803e-09j)\n",
      "\n",
      "U:    tensor([[ 0.7071+4.1778e-12j, -0.6875-1.6531e-01j],\n",
      "        [ 0.7071-3.8792e-12j,  0.6875+1.6531e-01j]], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Loss: (4.440892098500626e-16+4.223744975416693e-13j)\n",
      "\n",
      "U:    tensor([[ 0.7071-8.3267e-17j, -0.6875-1.6531e-01j],\n",
      "        [ 0.7071+6.9389e-17j,  0.6875+1.6531e-01j]], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "Loss: (4.440892098500626e-16-1.9626155733547183e-17j)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "q0 = torch.tensor([1,0], dtype=torch.complex128, requires_grad=False)\n",
    "\n",
    "α = torch.rand(1, dtype=torch.float64, requires_grad = True)\n",
    "β = torch.rand(1, dtype=torch.float64, requires_grad = True)\n",
    "θ = torch.rand(1, dtype=torch.float64, requires_grad = True)\n",
    "ϕ = torch.rand(1, dtype=torch.float64, requires_grad = True)\n",
    "\n",
    "# U = torch.rand(2,2, dtype=torch.complex128, requires_grad=True)\n",
    "H = torch.tensor([[1,1],[1,-1]] / np.sqrt(2), dtype=torch.complex128, requires_grad=False)\n",
    "\n",
    "def elements_to_matrix(matrix_entries: list):\n",
    "    return torch.stack([torch.stack([value for value in row]) for row in matrix_entries]).squeeze()\n",
    "    \n",
    "def quantum_infidelity(state, target_state):\n",
    "    return 1 - torch.dot(state.conj(), target_state)**2\n",
    "\n",
    "optimizer = torch.optim.Adam([α, β, θ, ϕ], lr=learning_rate)\n",
    "\n",
    "print(elements_to_matrix([[torch.tensor(1), torch.tensor(2)],[torch.tensor(3), torch.tensor(4)]]))\n",
    "\n",
    "for epoch in range(1000):\n",
    "    U = torch.exp(1j * ϕ / 2) * elements_to_matrix([\n",
    "        [torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "        [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]\n",
    "    ])\n",
    "    q0_out = U.matmul(q0)\n",
    "    q0_target = H.matmul(q0)\n",
    "    loss = quantum_infidelity(q0_out, q0_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"U:    {U}\")\n",
    "        print(f\"Loss: {loss}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09de9d9b-2c42-452c-99b2-438d291775c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.+0.j, 0.+0.j], dtype=torch.complex128)\n",
      "tensor([0.7071+0.0000e+00j, 0.7071-1.3878e-17j], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(q0)\n",
    "    print(U.matmul(q0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f08d530-29ed-4adb-9678-8917305dc3dd",
   "metadata": {},
   "source": [
    "## Using `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "271f4230-5d70-42d7-8163-4f82709a6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleQubitGate(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.α = torch.nn.Parameter(torch.rand(1, dtype=torch.float64, requires_grad = True))\n",
    "        self.β = torch.nn.Parameter(torch.rand(1, dtype=torch.float64, requires_grad = True))\n",
    "        self.θ = torch.nn.Parameter(torch.rand(1, dtype=torch.float64, requires_grad = True))\n",
    "        self.ϕ = torch.nn.Parameter(torch.rand(1, dtype=torch.float64, requires_grad = True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 1: # a single vector\n",
    "            return self._forward_single(x)\n",
    "        else:\n",
    "            return self._forward_batch(x)\n",
    "        \n",
    "    def _forward_single(self, x):\n",
    "        α, β, θ, ϕ = self.α, self.β, self.θ, self.ϕ\n",
    "        U = torch.exp(1j * ϕ / 2) * elements_to_matrix([\n",
    "            [torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "            [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]\n",
    "        ])\n",
    "        return U.matmul(x)\n",
    "    \n",
    "    def _forward_batch(self, x_batch):\n",
    "        α, β, θ, ϕ = self.α, self.β, self.θ, self.ϕ\n",
    "        U = torch.exp(1j * ϕ / 2) * elements_to_matrix([\n",
    "            [torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "            [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]\n",
    "        ])\n",
    "        return torch.einsum('ij,bj->bi', U, x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc98d14-8902-4fb9-95b1-05b78c9b9327",
   "metadata": {},
   "source": [
    "### Train on single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b7a32f22-d0e3-4ad0-b257-085258ead328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: (1.0583467340989674+0.23948364300654784j)\n",
      "Loss: (1.1296647650649305e-07-7.164701218646363e-06j)\n",
      "Loss: (4.440892098500626e-16+8.671024406699302e-10j)\n",
      "Loss: (4.440892098500626e-16-3.41495109763721e-14j)\n",
      "Loss: (2.220446049250313e-16+9.813077866773592e-18j)\n",
      "tensor([1.+0.j, 0.+0.j], dtype=torch.complex128)\n",
      "tensor([0.7071-6.9389e-18j, 0.7071+1.3878e-17j], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "model = SingleQubitGate()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    q0_out = model.forward(q0)\n",
    "    q0_target = H.matmul(q0)\n",
    "    loss = quantum_infidelity(q0_out, q0_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Loss: {loss}\")\n",
    "        \n",
    "with torch.no_grad():\n",
    "    print(q0)\n",
    "    print(model.forward(q0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a9ec12-a873-4316-a474-3ad668401861",
   "metadata": {},
   "source": [
    "### Using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "35c9f00b-aa6e-46a5-b783-9b9d40a0c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('qubit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9ecde80a-0fcf-4318-addc-edd45979a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "class QubitDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.df = pd.read_csv('qubit.csv')\n",
    "        self.df['input1'] = self.df['input1'].astype(complex)\n",
    "        self.df['input2'] = self.df['input2'].astype(complex)\n",
    "        self.df['output1'] = self.df['output1'].astype(complex)\n",
    "        self.df['output2'] = self.df['output2'].astype(complex)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            dataset.append([self.df['input1'][i],self.df['input2'][i]])\n",
    "            \n",
    "        self.dataset = torch.tensor(dataset, dtype=torch.complex128)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            labels.append([self.df['output1'][i],self.df['output2'][i]])\n",
    "        \n",
    "        self.labels = torch.tensor(labels, dtype=torch.complex128)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "\n",
    "data_set = QubitDataset()\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "441eca26-7e58-4ada-8f83-072de4bf7ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6161921476104731\n",
      "Loss: 0.43762730818361684\n",
      "Loss: 0.5680465862271575\n",
      "Loss: 0.385148277416396\n",
      "Loss: 0.37380097606240853\n",
      "tensor([1.+0.j, 0.+0.j], dtype=torch.complex128)\n",
      "tensor([-0.0430-0.0056j,  0.9884+0.1454j], dtype=torch.complex128)\n"
     ]
    }
   ],
   "source": [
    "model = SingleQubitGate()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch):\n",
    "    return torch.stack([torch.abs(1 - torch.abs(torch.dot(state.conj(), target_state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for batch, labels in data_loader:\n",
    "        # print(batch)\n",
    "        # print(labels)\n",
    "        outputs = model(batch)\n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Loss: {loss}\")\n",
    "        # print(outputs)\n",
    "        # print(labels)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    print(q0)\n",
    "    print(model.forward(q0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66872696-9d3d-41fe-8e4d-63c050e12827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
