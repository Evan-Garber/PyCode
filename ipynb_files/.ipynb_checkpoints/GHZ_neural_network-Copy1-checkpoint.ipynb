{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196613f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fields = ['input1', 'input2','output1', 'output2']\n",
    "rows = []\n",
    "h_target = torch.tensor([[1.,1.],[1.,-1]] / np.sqrt(2), dtype=torch.complex128)\n",
    "x_target = torch.tensor([[0.,1.],[1.,0.]], dtype=torch.complex128)\n",
    "z_target = torch.tensor([[1.,0.],[0.,-1.]], dtype=torch.complex128)\n",
    "\n",
    "for i in range(8):\n",
    "    phi = np.random.rand() * 2*np.pi\n",
    "    theta = np.random.rand() * np.pi\n",
    "    \n",
    "    input_qubit = torch.tensor([np.sin(theta), np.cos(theta) * np.exp(1j * phi)])\n",
    "    output = h_target @ input_qubit\n",
    "\n",
    "    rows.append([np.sin(theta), np.cos(theta) * np.exp(1j * phi), output[0].item(), output[1].item()])\n",
    "\n",
    "filename = 'qubit.csv'\n",
    "\n",
    "with open(filename, 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n",
    "    csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e1a404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "      <th>output1</th>\n",
       "      <th>output2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.474827</td>\n",
       "      <td>(0.38476741900497863-0.7915131619412096j)</td>\n",
       "      <td>(0.6078252421634905-0.5596843242070352j)</td>\n",
       "      <td>(0.06368193984735848+0.5596843242070352j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388409</td>\n",
       "      <td>(0.40119195337626873-0.8295681435420967j)</td>\n",
       "      <td>(0.5583323346470785-0.5865932597549518j)</td>\n",
       "      <td>(-0.009038766932595088+0.5865932597549518j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.665070</td>\n",
       "      <td>(0.6913095309064529+0.2824412048650696j)</td>\n",
       "      <td>(0.9591051606432568+0.19971609124658957j)</td>\n",
       "      <td>(-0.018554153762431025-0.19971609124658957j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988384</td>\n",
       "      <td>(-0.07928075784657485+0.1296570154985216j)</td>\n",
       "      <td>(0.6428333135401408+0.0916813548874139j)</td>\n",
       "      <td>(0.7549532365219841-0.0916813548874139j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986524</td>\n",
       "      <td>(-0.13782214027122636-0.08817814766057389j)</td>\n",
       "      <td>(0.6001228650737823-0.062351366163260494j)</td>\n",
       "      <td>(0.7950328050406378+0.062351366163260494j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.751186</td>\n",
       "      <td>(0.5573526579942629-0.35366242710022183j)</td>\n",
       "      <td>(0.9252767918132208-0.2500771004534599j)</td>\n",
       "      <td>(0.13706110385304093+0.2500771004534599j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.737457</td>\n",
       "      <td>(-0.6475681575983349+0.19186778958112394j)</td>\n",
       "      <td>(0.06356072511214311+0.13567101510408633j)</td>\n",
       "      <td>(0.9793603961486661-0.13567101510408633j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.127826</td>\n",
       "      <td>(0.9828471417292867-0.13293646006793744j)</td>\n",
       "      <td>(0.7853642538084334-0.09400027238097325j)</td>\n",
       "      <td>(-0.6045915037647552+0.09400027238097325j)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input1                                       input2  \\\n",
       "0  0.474827    (0.38476741900497863-0.7915131619412096j)   \n",
       "1  0.388409    (0.40119195337626873-0.8295681435420967j)   \n",
       "2  0.665070     (0.6913095309064529+0.2824412048650696j)   \n",
       "3  0.988384   (-0.07928075784657485+0.1296570154985216j)   \n",
       "4  0.986524  (-0.13782214027122636-0.08817814766057389j)   \n",
       "5  0.751186    (0.5573526579942629-0.35366242710022183j)   \n",
       "6  0.737457   (-0.6475681575983349+0.19186778958112394j)   \n",
       "7  0.127826    (0.9828471417292867-0.13293646006793744j)   \n",
       "\n",
       "                                      output1  \\\n",
       "0    (0.6078252421634905-0.5596843242070352j)   \n",
       "1    (0.5583323346470785-0.5865932597549518j)   \n",
       "2   (0.9591051606432568+0.19971609124658957j)   \n",
       "3    (0.6428333135401408+0.0916813548874139j)   \n",
       "4  (0.6001228650737823-0.062351366163260494j)   \n",
       "5    (0.9252767918132208-0.2500771004534599j)   \n",
       "6  (0.06356072511214311+0.13567101510408633j)   \n",
       "7   (0.7853642538084334-0.09400027238097325j)   \n",
       "\n",
       "                                        output2  \n",
       "0     (0.06368193984735848+0.5596843242070352j)  \n",
       "1   (-0.009038766932595088+0.5865932597549518j)  \n",
       "2  (-0.018554153762431025-0.19971609124658957j)  \n",
       "3      (0.7549532365219841-0.0916813548874139j)  \n",
       "4    (0.7950328050406378+0.062351366163260494j)  \n",
       "5     (0.13706110385304093+0.2500771004534599j)  \n",
       "6     (0.9793603961486661-0.13567101510408633j)  \n",
       "7    (-0.6045915037647552+0.09400027238097325j)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('qubit.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6968175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.5377719933093592\n",
      "epoch: 500, loss: 8.881784197001252e-16\n",
      "tensor([-0.2954+0.6424j, -0.2954+0.6424j], dtype=torch.complex128,\n",
      "       grad_fn=<MvBackward0>)\n",
      "tensor([-0.2954+0.6424j,  0.0000+0.0000j,  0.0000+0.0000j, -0.2954+0.6424j],\n",
      "       dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n",
      "tensor([-0.2954+0.6424j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j, -0.2954+0.6424j],\n",
      "       dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n",
      "tensor([-0.2954+0.6424j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j, -0.2954+0.6424j],\n",
      "       dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "#There are 3 versions to this code: \n",
    "# with a global phase\n",
    "# without a global phase\n",
    "# without a global phase and a different matrix for U\n",
    "\n",
    "#This version has a global phase, but I'm not really sure how to get rid of it.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "\n",
    "num_qubits = 8\n",
    "\n",
    "n_ghz = 4\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "num_epochs = 501\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "class input_vec_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.df = pd.read_csv('qubit.csv')\n",
    "        self.df['input1'] = self.df['input1'].astype(complex)\n",
    "        self.df['input2'] = self.df['input2'].astype(complex)\n",
    "        self.df['output1'] = self.df['output1'].astype(complex)\n",
    "        self.df['output2'] = self.df['output2'].astype(complex)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_qubits):\n",
    "            dataset.append([self.df['input1'][i],self.df['input2'][i]])\n",
    "            \n",
    "        self.dataset = torch.tensor(dataset, dtype=torch.complex128)\n",
    "        \n",
    "        for i in range(num_qubits):\n",
    "            labels.append([self.df['output1'][i],self.df['output2'][i]])\n",
    "        \n",
    "        self.labels = torch.tensor(labels, dtype=torch.complex128)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "\n",
    "data_set = input_vec_dataset()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "def elements_to_matrix(matrix_entries: list):\n",
    "    return torch.stack([torch.stack([value for value in row]) for row in matrix_entries]).squeeze()\n",
    "\n",
    "class HModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HModel, self).__init__()\n",
    "        self.θ = Parameter(torch.rand(1, dtype=torch.float64))\n",
    "        self.α = Parameter(torch.rand(1, dtype=torch.float64))\n",
    "        self.β = Parameter(torch.rand(1, dtype=torch.float64))\n",
    "        self.ϕ = Parameter(torch.rand(1, dtype=torch.float64))\n",
    "      \n",
    "    def forward(self, x):\n",
    "        θ = self.θ\n",
    "        α = self.α\n",
    "        β = self.β\n",
    "        ϕ = self.ϕ\n",
    "        \n",
    "        U = torch.exp(1j * ϕ / 2) * elements_to_matrix(\n",
    "            [[torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "             [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]])\n",
    "        \n",
    "        if len(x.shape) == 1:\n",
    "            return U.matmul(x)\n",
    "        else:\n",
    "            return torch.einsum('ij,bj->bi', U, x)\n",
    "    \n",
    "model = HModel()\n",
    "\n",
    "c_not = torch.tensor([[1,0,0,0],\n",
    "                      [0,1,0,0],\n",
    "                      [0,0,0,1],\n",
    "                      [0,0,1,0]], dtype=torch.complex128)\n",
    "\n",
    "i = torch.tensor([[1,0],\n",
    "                  [0,1]], dtype=torch.complex128)\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch, include_global_phase=False):\n",
    "\n",
    "    if include_global_phase:\n",
    "        return torch.stack([\n",
    "            torch.abs((torch.angle(target_state - state))) * torch.abs(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                    for state, target_state in zip(state_batch, target_state_batch)\n",
    "        ]).mean()\n",
    "    else:\n",
    "        return torch.stack([torch.abs(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, labels in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch)\n",
    "        \n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        print(f'epoch: {epoch}, loss: {loss}')\n",
    "        \n",
    "    \n",
    "model.eval()\n",
    "\n",
    "q0 = model(torch.tensor([1,0],dtype=torch.complex128, requires_grad=False))\n",
    "q1 = torch.tensor([1,0],dtype=torch.complex128, requires_grad=False)\n",
    "print(q0)\n",
    "\n",
    "for n in range(n_ghz-1):\n",
    "    q0 = torch.kron(q0,q1)\n",
    "    q0 = q0 @ c_not\n",
    "    c_not = torch.kron(i,c_not)\n",
    "    print(q0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d579b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.3432470590721669\n",
      "epoch: 500, loss: 0.06547452034808056\n",
      "epoch: 1000, loss: 0.0037096270396033\n",
      "epoch: 1500, loss: 4.607493956802766e-05\n",
      "epoch: 2000, loss: 8.789398833752848e-08\n",
      "epoch: 2500, loss: 1.652170067423242e-11\n",
      "epoch: 3000, loss: 4.163336342344337e-16\n",
      "tensor([0.7071-1.6182e-17j, 0.7071-1.5323e-08j], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([0.7071-1.6182e-17j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.7071-1.5323e-08j], dtype=torch.complex128,\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "num_qubits = 8\n",
    "\n",
    "n_ghz = 4\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 3001\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_graph = []\n",
    "\n",
    "q1_graph = []\n",
    "q2_graph = []\n",
    "\n",
    "\n",
    "c_not = torch.tensor([[1,0,0,0],\n",
    "                      [0,1,0,0],\n",
    "                      [0,0,0,1],\n",
    "                      [0,0,1,0]], dtype=torch.complex128)\n",
    "\n",
    "i = torch.tensor([[1,0],\n",
    "                  [0,1]], dtype=torch.complex128)\n",
    "\n",
    "#===============================================================================================================================\n",
    "#Create the data set\n",
    "\n",
    "class input_vec_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.df = pd.read_csv('qubit.csv')\n",
    "        self.df['input1'] = self.df['input1'].astype(complex)\n",
    "        self.df['input2'] = self.df['input2'].astype(complex)\n",
    "        self.df['output1'] = self.df['output1'].astype(complex)\n",
    "        self.df['output2'] = self.df['output2'].astype(complex)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_qubits):\n",
    "            dataset.append([self.df['input1'][i],self.df['input2'][i]])\n",
    "            \n",
    "        self.dataset = torch.tensor(dataset, dtype=torch.complex128)\n",
    "        \n",
    "        for i in range(num_qubits):\n",
    "            labels.append([self.df['output1'][i],self.df['output2'][i]])\n",
    "        \n",
    "        self.labels = torch.tensor(labels, dtype=torch.complex128)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "    \n",
    "#===============================================================================================================================\n",
    "#Load the data set\n",
    "\n",
    "data_set = input_vec_dataset()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "#===============================================================================================================================\n",
    "\n",
    "def elements_to_matrix(matrix_entries: list):\n",
    "    return torch.stack([torch.stack([value for value in row]) for row in matrix_entries]).squeeze()\n",
    "\n",
    "#===============================================================================================================================\n",
    "#The model\n",
    "\n",
    "class HModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HModel, self).__init__()\n",
    "        self.θ = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.α = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.β = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.ϕ = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "      \n",
    "    def forward(self, x):\n",
    "        θ = self.θ\n",
    "        α = self.α\n",
    "        β = self.β\n",
    "        ϕ = self.ϕ\n",
    "\n",
    "        U = elements_to_matrix(\n",
    "            [[torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "             [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]])\n",
    "        \n",
    "        if len(x.shape) == 1:\n",
    "            return U.matmul(x)\n",
    "        else:\n",
    "            q_test = torch.tensor([1,0], dtype=torch.complex128, requires_grad=False)\n",
    "            out = U @ q_test\n",
    "            q1_graph.append(abs(out[0].tolist()))\n",
    "            q2_graph.append(abs(out[1].tolist()))\n",
    "            \n",
    "            return torch.einsum('ij,bj->bi', U, x)        \n",
    "\n",
    "#===============================================================================================================================\n",
    "#Loss function\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch):\n",
    "\n",
    "    loss = torch.stack([(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    fidelity = torch.stack([torch.abs(torch.dot(target_state.conj(), state))**2\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    loss_graph.append(fidelity.item())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "#===============================================================================================================================\n",
    "#Train the model\n",
    "\n",
    "model = HModel()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, labels in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch)\n",
    "        \n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        print(f'epoch: {epoch}, loss: {loss}')\n",
    "        \n",
    "#===============================================================================================================================\n",
    "#Test the model\n",
    "\n",
    "model.eval()\n",
    "\n",
    "q0 = model(torch.tensor([1,0],dtype=torch.complex128, requires_grad=False))\n",
    "q1 = torch.tensor([1,0],dtype=torch.complex128, requires_grad=False)\n",
    "\n",
    "fake_global_phase = torch.angle(q0[0])\n",
    "q0 = torch.exp(-1j * fake_global_phase) * q0\n",
    "print(q0)\n",
    "\n",
    "for n in range(n_ghz-1):\n",
    "    q0 = torch.kron(q0,q1)\n",
    "    q0 = q0 @ c_not\n",
    "    c_not = torch.kron(i,c_not)\n",
    "print(q0)\n",
    "\n",
    "#===============================================================================================================================\n",
    "#Graph the progress of the model\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(8,4), height_ratios=(1.5,1), layout='constrained')\n",
    "\n",
    "x_graph = np.arange(num_epochs * num_qubits / batch_size)\n",
    "y_graph = np.zeros(int(num_epochs * num_qubits / batch_size))\n",
    "\n",
    "q12_graph = np.array([q2_graph,q1_graph])\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "cs = ax2.pcolormesh(q12_graph, norm=norm, cmap='viridis')\n",
    "\n",
    "cbar = fig.colorbar(cs, ax=ax2, pad=0, aspect=8)\n",
    "cbar.set_ticks([0, 1/np.sqrt(2), 1])\n",
    "cbar.set_ticklabels([\"0\", \"1/√2\", \"1\"])\n",
    "\n",
    "ax2.set_yticks([0.5,1.5], labels=['|1⟩','|0⟩'])\n",
    "ax2.tick_params(left = False)\n",
    "\n",
    "ax1.set_title('Fidelity')\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_xlim(1,num_epochs * num_qubits / batch_size-1)\n",
    "ax1.plot(x_graph,loss_graph)\n",
    "ax1.fill_between(x_graph, loss_graph, alpha=0.3)\n",
    "\n",
    "#===============================================================================================================================\n",
    "#Suppress console output\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877279a2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f822252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.6075675094501105\n",
      "epoch: 500, loss: 0.052130496817883745\n",
      "epoch: 1000, loss: 0.02320172913401737\n",
      "epoch: 1500, loss: 0.01581278237248107\n",
      "epoch: 2000, loss: 0.010459663382475323\n",
      "epoch: 2500, loss: 0.006592592955255147\n",
      "epoch: 3000, loss: 0.004200843956813388\n",
      "tensor([ 0.2584+0.6050j, -0.0294+0.7776j], dtype=torch.complex128,\n",
      "       grad_fn=<MvBackward0>)\n",
      "tensor([ 0.2584+0.6050j,  0.0000+0.0000j,  0.0000+0.0000j, -0.0294+0.7776j],\n",
      "       dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n",
      "tensor([0.6579-2.7756e-17j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.7036+3.3251e-01j], dtype=torch.complex128, grad_fn=<MulBackward0>)\n",
      "tensor([ 0.2584+0.6050j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j, -0.0294+0.7776j],\n",
      "       dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n",
      "tensor([0.6579-2.7756e-17j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.7036+3.3251e-01j], dtype=torch.complex128,\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([ 0.2584+0.6050j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j,\n",
      "         0.0000+0.0000j,  0.0000+0.0000j,  0.0000+0.0000j, -0.0294+0.7776j],\n",
      "       dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n",
      "tensor([0.6579-2.7756e-17j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.0000+0.0000e+00j, 0.0000+0.0000e+00j, 0.0000+0.0000e+00j,\n",
      "        0.7036+3.3251e-01j], dtype=torch.complex128, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#This version uses a different matrix for U\n",
    "#It doesn't have any problems with being negative or having some rotation, but it isn't as accurate\n",
    "#It usually only gets so precise and takes considerably more epochs\n",
    "#It's not great, but it's good enough\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "\n",
    "num_qubits = 8\n",
    "\n",
    "n_ghz = 4\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "num_epochs = 1001\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "class input_vec_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.df = pd.read_csv('qubit.csv')\n",
    "        self.df['input1'] = self.df['input1'].astype(complex)\n",
    "        self.df['input2'] = self.df['input2'].astype(complex)\n",
    "        self.df['output1'] = self.df['output1'].astype(complex)\n",
    "        self.df['output2'] = self.df['output2'].astype(complex)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_qubits):\n",
    "            dataset.append([self.df['input1'][i],self.df['input2'][i]])\n",
    "            \n",
    "        self.dataset = torch.tensor(dataset, dtype=torch.complex128)\n",
    "        \n",
    "        for i in range(num_qubits):\n",
    "            labels.append([self.df['output1'][i],self.df['output2'][i]])\n",
    "        \n",
    "        self.labels = torch.tensor(labels, dtype=torch.complex128)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "\n",
    "data_set = input_vec_dataset()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "def elements_to_matrix(matrix_entries: list):\n",
    "    return torch.stack([torch.stack([value for value in row]) for row in matrix_entries]).squeeze()\n",
    "\n",
    "class HModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HModel, self).__init__()\n",
    "        self.θ = Parameter(torch.rand(1, dtype=torch.float64))\n",
    "        self.α = Parameter(torch.rand(1, dtype=torch.complex128))\n",
    "        self.β = Parameter(torch.rand(1, dtype=torch.complex128))\n",
    "        self.ϕ = Parameter(torch.rand(1, dtype=torch.float64))\n",
    "      \n",
    "    def forward(self, x):\n",
    "        θ = self.θ\n",
    "        α = self.α\n",
    "        β = self.β\n",
    "        ϕ = self.ϕ\n",
    "     \n",
    "        U = elements_to_matrix([[α,β],\n",
    "                                [-torch.exp(1j * ϕ) * β.conj(),torch.exp(1j * ϕ) * α.conj()]])\n",
    "\n",
    "        if len(x.shape) == 1:\n",
    "            return U.matmul(x)\n",
    "        else:\n",
    "            return torch.einsum('ij,bj->bi', U, x)\n",
    "    \n",
    "model = HModel()\n",
    "\n",
    "c_not = torch.tensor([[1,0,0,0],\n",
    "                      [0,1,0,0],\n",
    "                      [0,0,0,1],\n",
    "                      [0,0,1,0]], dtype=torch.complex128)\n",
    "\n",
    "i = torch.tensor([[1,0],\n",
    "                  [0,1]], dtype=torch.complex128)\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch):\n",
    "\n",
    "    return torch.stack([torch.abs(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, labels in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch)\n",
    "        \n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        print(f'epoch: {epoch}, loss: {loss}')\n",
    "        \n",
    "    \n",
    "model.eval()\n",
    "\n",
    "q0 = model(torch.tensor([1,0],dtype=torch.complex128, requires_grad=False))\n",
    "q1 = torch.tensor([1,0],dtype=torch.complex128, requires_grad=False)\n",
    "print(q0)\n",
    "\n",
    "for n in range(n_ghz-1):\n",
    "    q0 = torch.kron(q0,q1)\n",
    "    q0 = q0 @ c_not\n",
    "    c_not = torch.kron(i,c_not)\n",
    "    print(q0)\n",
    "    fake_global_phase = torch.angle(q0[0])\n",
    "    print(torch.exp(-1j * fake_global_phase) * q0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a91e7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QFT(qubits, num_ancillae = 0):\n",
    "    '''Applies quantum Fourier transform to inputs, then shuffles the output to be in the same order as input'''\n",
    "    N = len(qubits) - num_ancillae\n",
    "    for n in range(N):\n",
    "        target = qubits[n]\n",
    "        squanch.H(target)\n",
    "        for m in range(1, N - n):\n",
    "            squanch.CPHASE(qubits[n + m], target, 2 * np.pi / (2 ** (m + 1)))\n",
    "    # At this point, the output bits are in reverse order, so swap first with last and so on to get right order\n",
    "    for n in range(N // 2):\n",
    "        squanch.SWAP(qubits[n], qubits[N - n - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8095ba64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.309939691679161\n",
      "epoch: 500, loss: 0.09764366414853334\n",
      "epoch: 1000, loss: 0.0042036896514889704\n",
      "epoch: 1500, loss: 4.4020636376956856e-05\n",
      "epoch: 2000, loss: 8.441038032436232e-08\n",
      "epoch: 2500, loss: 1.6513235223669653e-11\n",
      "epoch: 3000, loss: 3.3306690738754696e-16\n",
      "tensor([-1.4107e-08-0.7071j, -4.3134e-09-0.7071j], dtype=torch.complex128,\n",
      "       grad_fn=<MvBackward0>)\n",
      "tensor([-1.4107e-08-0.7071j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "        -4.3134e-09-0.7071j], dtype=torch.complex128,\n",
      "       grad_fn=<SqueezeBackward4>)\n",
      "tensor([-1.4107e-08-0.7071j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "         0.0000e+00+0.0000j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "         0.0000e+00+0.0000j, -4.3134e-09-0.7071j], dtype=torch.complex128,\n",
      "       grad_fn=<SqueezeBackward4>)\n",
      "tensor([-1.4107e-08-0.7071j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "         0.0000e+00+0.0000j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "         0.0000e+00+0.0000j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "         0.0000e+00+0.0000j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "         0.0000e+00+0.0000j,  0.0000e+00+0.0000j,  0.0000e+00+0.0000j,\n",
      "        -4.3134e-09-0.7071j], dtype=torch.complex128,\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x263938f9910>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGdCAYAAAABhTmFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsIUlEQVR4nO3de3xU1b338e/kNuGSDJdILhBCUNBoFGtQCEoV1GBEWo+eI9YeUQs9pi0iRK0gfYqgbWhP5aGtgh4FbU+ppS3qsQ85SKwXUNBKDBUhKpVLUBIiEZOgkJBkPX+ETBkSkkyYyc6s+bxfr3lNZmftvX+zMjDf19p7r+0yxhgBAABYIMLpAgAAAAKFYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsEaU0wV0RlNTk/bv36+4uDi5XC6nywEAAJ1gjFFtba1SUlIUEdE9YykhEWz279+v1NRUp8sAAABdsG/fPg0ZMqRb9hUSwSYuLk5Sc8fEx8c7XA0AAOiMmpoapaamer/Hu0NIBJuWw0/x8fEEGwAAQkx3nkbCycMAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGv4HWw2bNigKVOmKCUlRS6XSy+88EKH67z++uvKyspSbGyshg8frscff7wrtQIAALTL72Dz5ZdfatSoUXr00Uc71X737t269tprNX78eJWUlOiBBx7QrFmztGbNGr+LBQAAaI/fMw/n5uYqNze30+0ff/xxDR06VEuXLpUkZWRkaMuWLfrFL36hG2+80d/dAwAAnFLQz7HZvHmzcnJyfJZNmjRJW7Zs0bFjx9pcp66uTjU1NT4PAACAjgQ92FRUVCgxMdFnWWJiohoaGnTw4ME21ykoKJDH4/E+uLM3AADojG65CebJN78yxrS5vMW8efOUn5/vfd1yd9DutH57hf7jv4vbbfPtMUP14DfOU3QkF5cBANATBD3YJCUlqaKiwmdZZWWloqKiNHDgwDbXcbvdcrvdwS7Nx+aPq/StJ9/ya51Vb5dp1dtlPss+/um1iozovruYAgCAfwp6sMnOztZf/vIXn2Xr16/X6NGjFR0dHezdt6u+oUkjf/S/Ad3mmQ8Uen/es3hyQLcNAADa5/cxlMOHD2vr1q3aunWrpObLubdu3aqysuaRi3nz5mnatGne9nl5edq7d6/y8/NVWlqqlStXasWKFbr33nsD8w5OQ6BDzcmGzV2rYXPXas/BL4O6HwAA0MzvEZstW7ZowoQJ3tct58LcdttteuaZZ1ReXu4NOZKUnp6uwsJCzZkzR4899phSUlL0q1/9Kqwu9b7iF69Jkn7znUt0+cgznC0GCDHGGBkjNRmjRmPU1CQda2pSQ6NRQ2OT6hubVN9wwnNDk44ea1J9Y6OOHmtSXUPz89FjjaprOMXzCe3qG5p0tKHx+HaOPzf8c9v1jU1OdwkQcHdcOkwLppzndBkB4TItZ/L2YDU1NfJ4PKqurlZ8fHzAtjts7tqAbcsf/3v3eGUkB+59AJ3R1GRU19Ck6iPHVFFzVGWff6WdB2q1fX+N3i07pC++anv6BQDh4enbL9aEcwYFdJvB+v5uT7dcFQVfub/cKEna+ZNcK66oMsbo0y+O6BcvfagXtu53upxOOWtQX00+P1ljhw/UiMS+6t87pkec9N3Q2KSDh+v14YFavb2rSuu2V2jXZxzKBBB8v/9bWcCDjRMINg4aMb/5HJ9QOcm4scnop4WlWvHGbqdLOW3/qDysX/51p375152ntZ2vDe2nG742WGOHD1T/PjH6qKJW63cc0DOb9gSmUACAXwg2PcCwuWu14b4JGjqwt9Ol+CivPqLsglecLqNHKyn7QiVlXzhdBgDgOIJND/H1/3xVkvOjN/Of39Zqbh4AAEIFwaaHGTZ3rT546BrFRkd22z5//3aZHnh+W7ftDwCAYCHY9EDn/J91+tHkDM0YPzxo+zDGKH1eYccNAQAIIQSbHurhtaV6eG2pJOnvC3Lk6RWYWZqP1Dcq48frArItAIA93t5V5XQJAUGwCQGjFq6XJM2ccJbunXR2l7ZxrLHJexUWAAAnqzna4HQJAUGwCSGPvvoPPfrqP5TQ160tP7qq0+s5NREhAADdLfRnhwtDBw/XadjctTq3g0NKv/rrTkINACCsMGITwr6qb9SwuWs16bxEPXHraO/yxibjc5dxAADCBcHGAi9tP6Bhc9fq6dsv1rZPq7Wk6COnSwIAwBEEG4vc8cw7TpcAAICjOMcGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1uhSsFm2bJnS09MVGxurrKwsbdy4sd32q1at0qhRo9S7d28lJyfrjjvuUFVVVZcKBgAAOBW/g83q1as1e/ZszZ8/XyUlJRo/frxyc3NVVlbWZvs33nhD06ZN0/Tp07V9+3b96U9/0jvvvKMZM2acdvEAAAAn8jvYLFmyRNOnT9eMGTOUkZGhpUuXKjU1VcuXL2+z/VtvvaVhw4Zp1qxZSk9P12WXXaY777xTW7ZsOe3iAQAATuRXsKmvr1dxcbFycnJ8lufk5GjTpk1trjNu3Dh98sknKiwslDFGBw4c0J///GdNnjy561UDAAC0wa9gc/DgQTU2NioxMdFneWJioioqKtpcZ9y4cVq1apWmTp2qmJgYJSUlqV+/fvr1r399yv3U1dWppqbG5wEAANCRLp087HK5fF4bY1ota7Fjxw7NmjVLP/7xj1VcXKx169Zp9+7dysvLO+X2CwoK5PF4vI/U1NSulAkAAMKMX8EmISFBkZGRrUZnKisrW43itCgoKNCll16q++67TxdccIEmTZqkZcuWaeXKlSovL29znXnz5qm6utr72Ldvnz9lAgCAMOVXsImJiVFWVpaKiop8lhcVFWncuHFtrvPVV18pIsJ3N5GRkZKaR3ra4na7FR8f7/MAAADoiN+HovLz8/XUU09p5cqVKi0t1Zw5c1RWVuY9tDRv3jxNmzbN237KlCl67rnntHz5cu3atUtvvvmmZs2apUsuuUQpKSmBeycAACDsRfm7wtSpU1VVVaVFixapvLxcmZmZKiwsVFpamiSpvLzcZ06b22+/XbW1tXr00Ud1zz33qF+/fpo4caJ+9rOfBe5dAAAASHKZUx0P6kFqamrk8XhUXV0d0MNSw+auDdi2AAAIdXsWB3YqlmB9f7eHe0UBAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGt0KdgsW7ZM6enpio2NVVZWljZu3Nhu+7q6Os2fP19paWlyu90688wztXLlyi4VDAAAcCpR/q6wevVqzZ49W8uWLdOll16qJ554Qrm5udqxY4eGDh3a5jo33XSTDhw4oBUrVuiss85SZWWlGhoaTrt4AACAE7mMMcafFcaMGaOLLrpIy5cv9y7LyMjQ9ddfr4KCglbt161bp5tvvlm7du3SgAEDulRkTU2NPB6PqqurFR8f36VttGXY3LUB2xYAAKFuz+LJAd1esL6/2+PXoaj6+noVFxcrJyfHZ3lOTo42bdrU5jovvviiRo8erZ///OcaPHiwRo4cqXvvvVdHjhw55X7q6upUU1Pj8wAAAOiIX4eiDh48qMbGRiUmJvosT0xMVEVFRZvr7Nq1S2+88YZiY2P1/PPP6+DBg/r+97+vzz///JTn2RQUFGjhwoX+lAYAANC1k4ddLpfPa2NMq2Utmpqa5HK5tGrVKl1yySW69tprtWTJEj3zzDOnHLWZN2+eqqurvY99+/Z1pUwAABBm/BqxSUhIUGRkZKvRmcrKylajOC2Sk5M1ePBgeTwe77KMjAwZY/TJJ59oxIgRrdZxu91yu93+lAYAAODfiE1MTIyysrJUVFTks7yoqEjjxo1rc51LL71U+/fv1+HDh73LPvroI0VERGjIkCFdKBkAAKBtfh+Kys/P11NPPaWVK1eqtLRUc+bMUVlZmfLy8iQ1H0aaNm2at/0tt9yigQMH6o477tCOHTu0YcMG3XffffrOd76jXr16Be6dAACAsOf3PDZTp05VVVWVFi1apPLycmVmZqqwsFBpaWmSpPLycpWVlXnb9+3bV0VFRbrrrrs0evRoDRw4UDfddJMefvjhwL0LAAAAdWEeGycwjw0AAMEXdvPYAAAA9GQEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGl0KNsuWLVN6erpiY2OVlZWljRs3dmq9N998U1FRUbrwwgu7slsAAIB2+R1sVq9erdmzZ2v+/PkqKSnR+PHjlZubq7KysnbXq66u1rRp03TllVd2uVgAAID2+B1slixZounTp2vGjBnKyMjQ0qVLlZqaquXLl7e73p133qlbbrlF2dnZXS4WAACgPX4Fm/r6ehUXFysnJ8dneU5OjjZt2nTK9Z5++ml9/PHHWrBgQaf2U1dXp5qaGp8HAABAR/wKNgcPHlRjY6MSExN9licmJqqioqLNdXbu3Km5c+dq1apVioqK6tR+CgoK5PF4vI/U1FR/ygQAAGGqSycPu1wun9fGmFbLJKmxsVG33HKLFi5cqJEjR3Z6+/PmzVN1dbX3sW/fvq6UCQAAwkznhlCOS0hIUGRkZKvRmcrKylajOJJUW1urLVu2qKSkRDNnzpQkNTU1yRijqKgorV+/XhMnTmy1ntvtltvt9qc0AAAA/0ZsYmJilJWVpaKiIp/lRUVFGjduXKv28fHx2rZtm7Zu3ep95OXl6eyzz9bWrVs1ZsyY06seAADgBH6N2EhSfn6+br31Vo0ePVrZ2dn6r//6L5WVlSkvL09S82GkTz/9VL/97W8VERGhzMxMn/UHDRqk2NjYVssBAABOl9/BZurUqaqqqtKiRYtUXl6uzMxMFRYWKi0tTZJUXl7e4Zw2AAAAweAyxhini+hITU2NPB6PqqurFR8fH7DtDpu7NmDbAgAg1O1ZPDmg2wvW93d7uFcUAACwBsEGAABYg2ADAACsQbABAADWINgAAABrEGwAAIA1CDYAAMAaBBsAAGANgg0AALAGwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANcI62EyK+JsWRP1Gma5dTpcCAAACIMrpApx0feSbyo18R5+aBL3fONzpcgAAwGkK6xGb0qY0SVJGRJnDlQAAgEAI72BjhkqSMlwEGwAAbECwkXSW6xNFq8HhagAAwOkK62DziTlDNaaXYlyNGuna53Q5Pt64f4I23DfB6TIAAAgpYR1sJJeKm0ZKksZEfOBwLb6G9O+toQN7O10GAAAhJcyDjfRW07mSpLEROxyu5J9Gp/X3/hznDusL1wAA8AvBpilDknRJxAdyqcnhapr9+XvjvD+/92COg5UAABBawj7YvG/SVWt6qZ/rS53Tw86zkSSXy+V0CQAAhIywDzaNitTfm5on57sw4h8OVyO9nP/1VsuenDbagUoAAAg9YR9sJKnEjJAkfc3lfLA5a1Bcq2VXn5voQCUAAIQego2krU1nSnJ+xOa8lHhH9w8AQKgj2Eja2nSWJOks13710lHH6vh/d112yt+9v3BSN1YCAEBoIthIqpJHn5l4RbiMznLtd6yO9k4U7stl3wAAdIhgc9zOpiGSpJGuTxzZf1snDZ9s6ujUbqgEAIDQRbA57iNzPNhEOHPJd1snDZ/sZ/96QTdUAgBA6CLYHLfTODdiM2qIp9v3CQCAjQg2x310/FCUE+fY/M/MU580fLK/3nN5ECsBACC0EWyO22Oa54pJdlUpSg0OV3NqZ57R1+kSAADosQg2x32mfjpqohXlalKKq6rb9vv2A1f6vU5MJH82AADawjekl0tlZpAkKc11oNv2mhgf6/c6Hzx0TRAqAQAg9BFsTtASbIa6Krtlf9+5NL1L60VEcGNMAADaQrA5Qdnx82xSuynY/HjKuV1e94lbswJYCQAAdiDYnMCJQ1FdNem8JKdLAACgxyHYnKAl2KS6Pgv6vjhPBgCAwCPYnKDcDJQkJbk+D/q+YqMjT3sbHz2cG4BKAACwB8HmBOVmgCQpwVUjt+qDtp8/5WUHZDsxUfz5AAA4Ed+MJ/hCfXXExEiSEl2Hgrafi4cNCNi2Fn3zvIBtCwCAUEew8eHyjtokKziHo8aPSAjo9qZlDwvo9gAACGUEm5O0nGeTHKTZh/97+pigbBcAABBsWqnQ8RGbbjiBOFC2L5zkdAkAAPQIBJuTtByKSgrCiM2HDwfnEu8+7qigbBcAgFBDsDlJy6GolCCM2LijTv8S71NZfMP5Qds2AAChgmBzkmCN2Lw5d2JAt3eymy8ZGtTtAwAQCroUbJYtW6b09HTFxsYqKytLGzduPGXb5557TldffbXOOOMMxcfHKzs7Wy+99FKXCw62f548HNgRm8H9egV0ewAAoDW/g83q1as1e/ZszZ8/XyUlJRo/frxyc3NVVlbWZvsNGzbo6quvVmFhoYqLizVhwgRNmTJFJSUlp118MFSY/pKaJ+mL0bGAbPPpOy4OyHY6wkzEAIBw53ewWbJkiaZPn64ZM2YoIyNDS5cuVWpqqpYvX95m+6VLl+qHP/yhLr74Yo0YMUI//elPNWLECP3lL3857eKD4ZDiVGeiJUmDXF8EZJsTzh4UkO10hJmIAQDhzq9vwvr6ehUXFysnJ8dneU5OjjZt2tSpbTQ1Nam2tlYDBpx69t26ujrV1NT4PLqPSwdMP0lSYgAm6fvR5IzT3oY/npo2ulv3BwBAT+JXsDl48KAaGxuVmJjoszwxMVEVFRWd2sYjjzyiL7/8UjfddNMp2xQUFMjj8Xgfqamp/pR52lrmskkKwG0VZowfftrb8MdV5yZ23AgAAEt16diFy+XyeW2MabWsLc8++6wefPBBrV69WoMGnfrwzLx581RdXe197Nu3rytldtmB4+fZnO5dvu+8vHtDTYuEvjGO7BcAAKf5FWwSEhIUGRnZanSmsrKy1SjOyVavXq3p06frj3/8o6666qp227rdbsXHx/s8ulPF8Uu+T/dGmPNyu/cwVIt35rffvwAA2MqvYBMTE6OsrCwVFRX5LC8qKtK4ceNOud6zzz6r22+/Xb///e81efLkrlUaBIWzxre5vCIAIzbfu+LMLq97ujozegYAgI38PhSVn5+vp556SitXrlRpaanmzJmjsrIy5eXlSWo+jDRt2jRv+2effVbTpk3TI488orFjx6qiokIVFRWqrq4O3LvoonNT2h4JOhCAEZv7rzmny+sGwtsPXOno/gEAcILfwWbq1KlaunSpFi1apAsvvFAbNmxQYWGh0tLSJEnl5eU+c9o88cQTamho0A9+8AMlJyd7H3fffXfg3sVpaGtGYO+ITRevivrlzReeTkkBkRgf63QJAAB0O5cxxjhdREdqamrk8XhUXV0dlPNths1d6/N6iKtSb7hnq85E6+y6ZyT5d2hnz+Kecbjt2b+Vad5z25wuAwAQIgL9/RXs7++2MKObpA8e8r3rduXxERu365j66bBf2wr2PaH88S3uHwUACDMEG0mx0b533a5XtKpMnCT/57LpafeESuKQFAAgjBBsjttdcK3P6wPeu3x3/jybk7fRE2ye13NGkAAACDaCzXEul0u//tbXvK9bTiDu7JVRP7/xgh55mXVPrAkAgGAh2JxgyqgU78/+Xhl108Xde9sHf5x8DhEAALYi2Jyk5XCSP4eiespVUKdy8jlEAADYimBzEpfLpe0LJ6lcnQs2//hJbneUddreuH+C0yUAABB0BJs29HFHacG3mu+31N5VUTt/kquoyNDowiH9eztdAgAAQRca38oO6HNG8zkziacYsdmzeLKiQyTUtFj9H2OdLgEAgKCKcrqAHisuWZI0wHVYex66UooO/flgxgwf6HQJAIAeqqfNw9ZVoTXk0J169ZeijoeZ2nJnawmgn914vtMlAAB6oMK7xztdQkAwYnMqLlfzqM2h3c3BZkC60xUFxNSLh+r+Ndw/Cuis3jGRGjqgt4b0762UfrE6o69bA/u61b93tOJ7RauvO0p93JGKjY6UOypSMVERio50KSoiQpERLrnU/N8Jc0oB3YNg0574lOZgU7Pf6UoC6v5rztHP1n3gdBmAX0al9lPOuYnKSuuv4Ql91L9PjKIiXAQGAD4INu05fp6NTYeiJOl7V5xJsEG3i3NHKT9npK7KSFRKv16KjCCQAAg8gk174o8Hmxq7go0k/fCas/XzdR86XQZCXP/e0frPfx2ly0YkMBEkgB6BYNOeuOO3WKi161CUJH3/irMINujQ0qkX6trzkxUTxXUGAEIDwaY9Fo/YSNJD3zxP/+d/tjtdBhyU7InVH+/MVuoAJnAEYAeCTXssHrGRpFuzhxFswsScq0bqBxPODJmZsgGgqwg27WkZsamtkIxpvmbTMr+bPkb/vuJtp8tAgJw1qK9e+MGl6uvmnzaA8MT/fu3pm9T83FgvfVUl9Ulwtp4guGyEfe8pXPzL1wbrF/82iquLAOAEBJv2RMVIfc6QvvyseS4bC4ONJG2eN1HZBa84XQY68P7CSYzEAEAH+F+yI3HJzcGmtlxKvsDpaoIi2WPH/UFs8sC15+i744cz+RwA+Ilg05H4FKniPetmHz7Zzp/kasT8/3W6jLD1+L9n6ZrMJKfLAICQR7DpiKWzD58smqtlutWPJmdoxvjhTpcBANYh2HQk/vgl35aP2EjSnsWTNWzuWqfLsFJ0pEsfPpSrCE70BYCgIth0JExGbFqsuG20pv9mi9NlWGH1f4zVmOEDnS4DAMIKwaYjls8+fLIrMxKdLiGkffDQNdwzCQAcRLDpiOWzD7flHz/J1VmcSNwpce4ovfdgDlcvAUAPQbDpSMuIzZFD0rEjUrT9l0ZHRUbo1rFp+u+39jpdSo90wRCPXpx5mdNlAADaQLDpSGw/KaqX1HCk+TybAeFxJctD12cSbE4wuF8vvTl3otNlAAA6QLDpiMvVPGrz+a7m82zCJNhIzG0jSbsLruUwEwCEEIJNZ8QPbg421Z84XUm3io6M0MJvnKcFL4bXHcD/viBHnl7RTpcBAOgCZmXrjJZRms8/drYOB9w2bpjTJXSLR2/5mvYsnqw9iycTagAghDFi0xkDz2p+rvqHs3U4xOaJ+/Ysnux0CQCAACLYdEaYBxtJKl10jTJ+vM7pMgLi5fzLddagvk6XAQAIAoJNZww8s/m5apdkTPMJxWGmV0yk/pSXrX97fLPTpXQZozMAYD+CTWf0Hya5IqT6WulwpRQXnrPzXjxsgGZclq6n3tjtdCmdtuZ745SV1t/pMgAA3YRg0xlRbqnfUOnQnubDUWEabCTpR9edq6LSA9pb9ZXTpbSLy7QBIDxxVVRnDWg5HLXT2Tp6gNfvm9Ajj8bd+fXh3iubCDUAEJ4YsemsM86WPv6rVPmB05X0CLsLJmviL17TroNfOl2K/vbAlRoUH+t0GQCAHoBg01mJmc3PB953to4e5JV7r9DSlz/S0pedGcXiZGAAwMkINp2VdDzYVGwL2yuj2jL7qpG68aIhGv/zV7tlf09NG62rzg3fc5wAAO0j2HTWGedIEVHS0S+ab63QL9XpinqM1AG9gz6JHycDAwA6g2DTWVFuKeFsqXJ78+Eogk0rexZPVmXtUV3yk78GZHub501UsqdXQLYFAAgPBBt/JJ3fHGzK/y6dnet0NT3SoLhY7Vk8WXUNjTr7R/7PVPzegzmKj+VeTQCAriHY+GPIaOm9P0hlbzldSY/njor0Obn3k0Nf6f8W7dSad5vvkD7pvETdNXGEzkuJ5xATACBgCDb+GDq2+fmTd6TGBimS7uusIf1765GbRumRm0Y5XQoAwGJM0OePQedKbo9Uf1g6sM3pagAAwEkINv6IiJSGjmn+ee8mZ2sBAACtEGz8lX558/NHLzlbBwAAaIVg46+Wq6H2vikd+cLRUgAAgC+Cjb8Gntk8WV9Tg7RzvdPVAACAExBsuiLjG83PJb9ztg4AAOCDYNMVF90qySXtfl2q+tjpagAAwHEEm67oN1QacXXzz28scbYWAADgRbDpqq//sPl56++b7/gNAAAc16Vgs2zZMqWnpys2NlZZWVnauHFju+1ff/11ZWVlKTY2VsOHD9fjjz/epWJ7lNSLm8+1MU3Smu9KdYedrggAgLDnd7BZvXq1Zs+erfnz56ukpETjx49Xbm6uysrK2my/e/duXXvttRo/frxKSkr0wAMPaNasWVqzZs1pF++4yUukvonSZ6XS726UDlc6XREAAGHNZYwx/qwwZswYXXTRRVq+fLl3WUZGhq6//noVFBS0an///ffrxRdfVGlpqXdZXl6e/v73v2vz5s2d2mdNTY08Ho+qq6sVHx/vT7nB92mx9Nt/keqqpV4DpLHfl877l+bLwrm5IwAgjDnx/e3XXRzr6+tVXFysuXPn+izPycnRpk1t32Jg8+bNysnJ8Vk2adIkrVixQseOHVN0dHSrderq6lRXV+d9XVNT40+Z3WtwlvSdddKaGVLldunVh5sfsR5pwHCp90DJHSdF95EiIiTXSQ+5gh+A+g2Vsn8Q3H0AANAD+BVsDh48qMbGRiUmJvosT0xMVEVFRZvrVFRUtNm+oaFBBw8eVHJycqt1CgoKtHDhQn9Kc1biudKdr0vvPydt/Z20d7N0tFraX+J0Zc0GjybYAADCgl/BpoXrpBEGY0yrZR21b2t5i3nz5ik/P9/7uqamRqmpqV0ptftERkujpjY/jh2RPt8tHdrTHHDqaqT6L5tPNDbm+HPj8eem4NcWPzj4+wAAoAfwK9gkJCQoMjKy1ehMZWVlq1GZFklJSW22j4qK0sCBA9tcx+12y+12+1NazxLdq3kUJ/FcpysBACCs+HVVVExMjLKyslRUVOSzvKioSOPGjWtznezs7Fbt169fr9GjR7d5fg0AAEBX+X25d35+vp566imtXLlSpaWlmjNnjsrKypSXlyep+TDStGnTvO3z8vK0d+9e5efnq7S0VCtXrtSKFSt07733Bu5dAAAAqAvn2EydOlVVVVVatGiRysvLlZmZqcLCQqWlpUmSysvLfea0SU9PV2FhoebMmaPHHntMKSkp+tWvfqUbb7wxcO8CAABAXZjHxgk9eh4bAADQJie+v7lXFAAAsAbBBgAAWINgAwAArEGwAQAA1iDYAAAAaxBsAACANQg2AADAGgQbAABgDYINAACwht+3VHBCy+TINTU1DlcCAAA6q+V7uztvchASwaa2tlaSlJqa6nAlAADAX7W1tfJ4PN2yr5C4V1RTU5P279+vuLg4uVyugG23pqZGqamp2rdvH/eg6kb0uzPod2fQ786g351xcr8bY1RbW6uUlBRFRHTP2S8hMWITERGhIUOGBG378fHxfPAdQL87g353Bv3uDPrdGSf2e3eN1LTg5GEAAGANgg0AALBGWAcbt9utBQsWyO12O11KWKHfnUG/O4N+dwb97oye0O8hcfIwAABAZ4T1iA0AALALwQYAAFiDYAMAAKxBsAEAANYI62CzbNkypaenKzY2VllZWdq4caPTJYWMBx98UC6Xy+eRlJTk/b0xRg8++KBSUlLUq1cvXXHFFdq+fbvPNurq6nTXXXcpISFBffr00Te+8Q198sknPm0OHTqkW2+9VR6PRx6PR7feequ++OKL7niLPcKGDRs0ZcoUpaSkyOVy6YUXXvD5fXf2c1lZmaZMmaI+ffooISFBs2bNUn19fTDetuM66vfbb7+91ed/7NixPm3od/8UFBTo4osvVlxcnAYNGqTrr79eH374oU8bPu+B15l+D7nPuwlTf/jDH0x0dLR58sknzY4dO8zdd99t+vTpY/bu3et0aSFhwYIF5rzzzjPl5eXeR2Vlpff3ixcvNnFxcWbNmjVm27ZtZurUqSY5OdnU1NR42+Tl5ZnBgweboqIi8+6775oJEyaYUaNGmYaGBm+ba665xmRmZppNmzaZTZs2mczMTHPdddd163t1UmFhoZk/f75Zs2aNkWSef/55n993Vz83NDSYzMxMM2HCBPPuu++aoqIik5KSYmbOnBn0PnBCR/1+2223mWuuucbn819VVeXThn73z6RJk8zTTz9t3n//fbN161YzefJkM3ToUHP48GFvGz7vgdeZfg+1z3vYBptLLrnE5OXl+Sw755xzzNy5cx2qKLQsWLDAjBo1qs3fNTU1maSkJLN48WLvsqNHjxqPx2Mef/xxY4wxX3zxhYmOjjZ/+MMfvG0+/fRTExERYdatW2eMMWbHjh1Gknnrrbe8bTZv3mwkmQ8++CAI76pnO/kLtjv7ubCw0ERERJhPP/3U2+bZZ581brfbVFdXB+X99hSnCjbf/OY3T7kO/X76KisrjSTz+uuvG2P4vHeXk/vdmND7vIfloaj6+noVFxcrJyfHZ3lOTo42bdrkUFWhZ+fOnUpJSVF6erpuvvlm7dq1S5K0e/duVVRU+PSv2+3W5Zdf7u3f4uJiHTt2zKdNSkqKMjMzvW02b94sj8ejMWPGeNuMHTtWHo+Hv5O6t583b96szMxMpaSkeNtMmjRJdXV1Ki4uDur77Klee+01DRo0SCNHjtR3v/tdVVZWen9Hv5++6upqSdKAAQMk8XnvLif3e4tQ+ryHZbA5ePCgGhsblZiY6LM8MTFRFRUVDlUVWsaMGaPf/va3eumll/Tkk0+qoqJC48aNU1VVlbcP2+vfiooKxcTEqH///u22GTRoUKt9Dxo0iL+T1K39XFFR0Wo//fv3V0xMTFj+LXJzc7Vq1Sq98soreuSRR/TOO+9o4sSJqqurk0S/ny5jjPLz83XZZZcpMzNTEp/37tBWv0uh93kPibt7B4vL5fJ5bYxptQxty83N9f58/vnnKzs7W2eeeaZ+85vfeE8q60r/ntymrfb8nXx1Vz/zt/inqVOnen/OzMzU6NGjlZaWprVr1+qGG2445Xr0e+fMnDlT7733nt54441Wv+PzHjyn6vdQ+7yH5YhNQkKCIiMjWyXAysrKVmkRndOnTx+df/752rlzp/fqqPb6NykpSfX19Tp06FC7bQ4cONBqX5999hl/J6lb+zkpKanVfg4dOqRjx47xt5CUnJystLQ07dy5UxL9fjruuusuvfjii3r11Vc1ZMgQ73I+78F1qn5vS0//vIdlsImJiVFWVpaKiop8lhcVFWncuHEOVRXa6urqVFpaquTkZKWnpyspKcmnf+vr6/X66697+zcrK0vR0dE+bcrLy/X+++9722RnZ6u6ulp/+9vfvG3efvttVVdX83eSurWfs7Oz9f7776u8vNzbZv369XK73crKygrq+wwFVVVV2rdvn5KTkyXR711hjNHMmTP13HPP6ZVXXlF6errP7/m8B0dH/d6WHv957/RpxpZpudx7xYoVZseOHWb27NmmT58+Zs+ePU6XFhLuuece89prr5ldu3aZt956y1x33XUmLi7O23+LFy82Ho/HPPfcc2bbtm3mW9/6VpuXZQ4ZMsS8/PLL5t133zUTJ05s8/LACy64wGzevNls3rzZnH/++WF1uXdtba0pKSkxJSUlRpJZsmSJKSkp8U5L0F393HIZ5pVXXmneffdd8/LLL5shQ4ZYefmrMe33e21trbnnnnvMpk2bzO7du82rr75qsrOzzeDBg+n30/C9733PeDwe89prr/lcVvzVV1952/B5D7yO+j0UP+9hG2yMMeaxxx4zaWlpJiYmxlx00UU+l7ehfS3zR0RHR5uUlBRzww03mO3bt3t/39TUZBYsWGCSkpKM2+02X//61822bdt8tnHkyBEzc+ZMM2DAANOrVy9z3XXXmbKyMp82VVVV5tvf/raJi4szcXFx5tvf/rY5dOhQd7zFHuHVV181klo9brvtNmNM9/bz3r17zeTJk02vXr3MgAEDzMyZM83Ro0eD+fYd016/f/XVVyYnJ8ecccYZJjo62gwdOtTcdtttrfqUfvdPW/0tyTz99NPeNnzeA6+jfg/Fz7vr+BsDAAAIeWF5jg0AALATwQYAAFiDYAMAAKxBsAEAANYg2AAAAGsQbAAAgDUINgAAwBoEGwAAYA2CDQAAsAbBBgAAWINgAwAArEGwAQAA1vj/D02y1bIaH9AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This version has no global phase.\n",
    "#One problem I encountered is that whenever I run it, the output is always [0+1j, 0+1j] / sqrt(2)\n",
    "#I found a way to fix it, which I explain below\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_qubits = 8\n",
    "\n",
    "n_ghz = 4\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 3001\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "class input_vec_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.df = pd.read_csv('qubit.csv')\n",
    "        self.df['input1'] = self.df['input1'].astype(complex)\n",
    "        self.df['input2'] = self.df['input2'].astype(complex)\n",
    "        self.df['output1'] = self.df['output1'].astype(complex)\n",
    "        self.df['output2'] = self.df['output2'].astype(complex)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_qubits):\n",
    "            dataset.append([self.df['input1'][i],self.df['input2'][i]])\n",
    "            \n",
    "        self.dataset = torch.tensor(dataset, dtype=torch.complex128)\n",
    "        \n",
    "        for i in range(num_qubits):\n",
    "            labels.append([self.df['output1'][i],self.df['output2'][i]])\n",
    "        \n",
    "        self.labels = torch.tensor(labels, dtype=torch.complex128)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "\n",
    "data_set = input_vec_dataset()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "def elements_to_matrix(matrix_entries: list):\n",
    "    return torch.stack([torch.stack([value for value in row]) for row in matrix_entries]).squeeze()\n",
    "\n",
    "class HModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HModel, self).__init__()\n",
    "        self.θ = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.α = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.β = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.ϕ = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "      \n",
    "    def forward(self, x):\n",
    "        θ = self.θ\n",
    "        α = self.α\n",
    "        β = self.β\n",
    "        ϕ = self.ϕ\n",
    "        \n",
    "        y = torch.tensor([[0,-1j],[1j,0]], dtype=torch.complex128) \n",
    "        \n",
    "        U = elements_to_matrix(\n",
    "            [[torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "             [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]])\n",
    "        \n",
    "#         U = U @ y\n",
    "        #For whatever reason, if I don't multiply by y, \n",
    "        #the output is always [0+1j, 0+1j] / sqrt(2) instead of [1+0j, 1+0j] / sqrt2\n",
    "        #However, even after multiplying by y, the output is occasionally negative\n",
    "        \n",
    "        if len(x.shape) == 1:\n",
    "            return U.matmul(x)\n",
    "        else:\n",
    "            return torch.einsum('ij,bj->bi', U, x)\n",
    "    \n",
    "model = HModel()\n",
    "\n",
    "c_not = torch.tensor([[1,0,0,0],\n",
    "                      [0,1,0,0],\n",
    "                      [0,0,0,1],\n",
    "                      [0,0,1,0]], dtype=torch.complex128)\n",
    "\n",
    "i = torch.tensor([[1,0],\n",
    "                  [0,1]], dtype=torch.complex128)\n",
    "\n",
    "loss_graph = []\n",
    "loss2_graph = []\n",
    "\n",
    "q1_graph = []\n",
    "q2_graph = []\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch):\n",
    "\n",
    "    loss = torch.stack([(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    fidelity = torch.stack([torch.abs(torch.dot(target_state.conj(), state))**2\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    loss_graph.append(fidelity.item())\n",
    "    \n",
    "    loss2_graph.append(loss.item())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, labels in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch)\n",
    "        \n",
    "        for a in range(batch_size):\n",
    "            \n",
    "            q1_graph.append(abs(outputs[a,0].tolist()))\n",
    "            q2_graph.append(abs(outputs[a,1].tolist()))\n",
    "        \n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        print(f'epoch: {epoch}, loss: {loss}')\n",
    "        \n",
    "\n",
    "model.eval()\n",
    "\n",
    "q0 = model(torch.tensor([1,0],dtype=torch.complex128, requires_grad=False))\n",
    "q1 = torch.tensor([1,0],dtype=torch.complex128, requires_grad=False)\n",
    "print(q0)\n",
    "\n",
    "for n in range(n_ghz-1):\n",
    "    q0 = torch.kron(q0,q1)\n",
    "    q0 = q0 @ c_not\n",
    "    c_not = torch.kron(i,c_not)\n",
    "    print(q0)\n",
    "#     fake_global_phase = torch.angle(q0[0])\n",
    "#     print(torch.exp(-1j * fake_global_phase) * q0)\n",
    "\n",
    "x_qubit_graph = np.arange(num_epochs * batch_size)\n",
    "x_loss_graph = np.arange(num_epochs * num_qubits / batch_size)\n",
    "\n",
    "plt.plot(x_qubit_graph,q1_graph)\n",
    "plt.plot(x_loss_graph,loss2_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9f19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
