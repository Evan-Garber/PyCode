{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6968175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.5276175486282239\n",
      "epoch: 500, loss: 0.00033057908065908803\n",
      "epoch: 1000, loss: 0.002722620006211207\n",
      "epoch: 1500, loss: 0.001057391792826226\n",
      "epoch: 2000, loss: 0.0002516506516289929\n",
      "tensor([0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j, 0.3536+0.j,\n",
      "        0.3536+0.j], dtype=torch.complex128, grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab30727190>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAMUlEQVR4nO3deXxU1cH/8e9kmywkAyGQhYQQkE1AxKAIKu6puFJ9FJcHRYFKWxdE+yg/a219fB5sbSm2CmoFlWoLfSruVBta9kUggrIvsiSELCSQPZlJZu7vj5AhQxJIIDhzbz7v12tempt7Z87JneF855xzz7UZhmEIAADAT4L8XQAAANCxEUYAAIBfEUYAAIBfEUYAAIBfEUYAAIBfEUYAAIBfEUYAAIBfEUYAAIBfhfi7AK3h8Xh0+PBhRUdHy2az+bs4AACgFQzDUHl5uZKSkhQU1HL/hynCyOHDh5WSkuLvYgAAgDOQk5Oj5OTkFn/f5jCyYsUKvfzyy8rKylJeXp4+/PBDjR07tsX98/Ly9OSTTyorK0t79uzRY489plmzZrXpNaOjoyXVVyYmJqatRQYAAH5QVlamlJQUbzvekjaHkcrKSg0dOlQPPvig7rjjjtPu73Q61a1bNz377LP6/e9/39aXkyTv0ExMTAxhBAAAkzndFIs2h5ExY8ZozJgxrd6/V69eeuWVVyRJ8+bNa+vLAQAAiwvIOSNOp1NOp9P7c1lZmR9LAwAAzqWAvLR3xowZcjgc3geTVwEAsK6ADCPTp09XaWmp95GTk+PvIgEAgHMkIIdp7Ha77Ha7v4sBAAC+BwHZMwIAADqONveMVFRUaO/evd6f9+/fr82bNys2NlY9e/bU9OnTlZubq/nz53v32bx5s/fYI0eOaPPmzQoLC9P5559/9jUAAACmZjMMw2jLAcuWLdPVV1/dZPsDDzygd955RxMmTNCBAwe0bNmyEy/SzPXFqampOnDgQKtes6ysTA6HQ6WlpawzAgCASbS2/W5zGPEHwggAAObT2vabOSMAAMCvCCMAAMCvCCMAAMCvCCMWUlBWo9eW7tXRSpe/iwIAQKsRRizkmQ++1ctf7tKP5m/0d1EAAGg1woiFLN11RJK08eAxP5cEAIDWI4xYSHgopxMAYD60XhYS+CvGAADQFGHEQggjAAAzIoxYiIc0AgAwIcKIhRBFAABmRBgBAAB+RRixkOCgpndHBgAg0BFGLCSEMAIAMCHCiIUE2wgjAADzIYxYSHDwiTDi8TCdFQBgDoQRC2k8TONye/xYEgAAWo8wYiHBhBEAgAkRRiwkqNGcEVcdYQQAYA6EEQtpvAIrYQQAYBaEEQtpPDJDGAEAmAVhxEJ8ekaYMwIAMAnCiIXUNQog9IwAAMyCMGIhjZcWqWOdEQCASRBGLMTdKIDUMUwDADAJwoiFuBvNGal10zMCADAHwoiFNF4Cvs5DzwgAwBwIIxbSuGekjp4RAIBJEEYswjAMNcoiqmXOCADAJAgjFuE+6eoZrqYBAJgFYcQiGg/RSPSMAADMgzBiESfPV2XOCADALAgjFnFyzwhX0wAAzIIwYhEnzxlhnREAgFkQRizCc/IEVuaMAABMgjBiESdfPcPVNAAAsyCMWISnydU0hpbtKtQTCzerpMrlp1IBAHB6If4uANpHk3VG3B5NeHuDJMkmaea4C7//QgEA0Ar0jFhEkwmsjX7+7kjF910cAABajTBiEU2HaU5MYHXWMZkVABC4CCMWcXLPSKWz7sT/u+pO3v2MZRdXaW9hebs9HwAAhBGLOLlnpKLmRADxeKSCshqt/a5YhnHmV9kcq3Rp9MtLddurq1VaXasKZ/uFHABAx0UYsYiTlxUpaxRGqmvdmrpgs+750zr9PetQq55v++EyPfPBtzpS7vRu25FfJkmqdLmV8fvlGvbCP7U1t/TsCx/AuMcP2uoXH2/Vba+t1rFKl5buKtTO458bAC0jjFjEycM0Fc5a7/+X19Rq7b5iSdIn3xxu1fM9tmCTFmzI0f3z1kuS1nxXpB15J4ZnCsqcqnUbWrqz8GyLLknKK63W1AWbtGZv0Vk/1zc5Jco5WnXWz7Mjr0zDX1yiaQs365G/fK0fzd/Y5O+ME3KOVmnsa6v1+vLv/F2UduP2GPrs28M6WFyprINH9e2hklPuX1zh1Py1B/VNTome/uBbPfj2Bt33p6/krHMrv7SmyeKEZmQYhjbnlKikyqXCshqfLywdwaFjVfqfz7frYHGlv4tiKW0OIytWrNAtt9yipKQk2Ww2ffTRR6c9Zvny5UpPT1d4eLh69+6t119//UzKilM4eZimvFHPSOOl4Q1D+nhzrlbtKVK1y93sc/1tY472FtZfgbMjr0w3zFqhe//0lf77s+1N9v18S54e/vNGbw9JztEq1dQ2/7yn8u6ag/po82Hd+9ZXkqQKZ51e+sdOvbvmgCbP36i13xW3qhfmYHGlxs5erZv/uErlNfWB7OPNufpoU67Gz/1Kbyz/TvNW7Vdxhe8/oMUVTn20Kde7cm1JlUvz1x5UaXWtFm3K1Wff5umf2wv0w9mrdc3vljUJO8t2FeqeN9dp22Fr9xT94V97NOHt9Sosr2nyuzdWfKfNOSV66R87z2gF4KOVLt0wa4Umz9/oHU78eHOusg4ePetyN6fO7VFpVe0p93n/q4N65C+bdMOslbpjzlrd9cZavfjZdv34vSyV1Zw4dm9huf7r799o8ZY877Z/bi+QJBVXuvTiZzt06Yx/6dWle89JXRqrdXv05N++0fMfb/X+Hb/JKWm3HppPvjmssa+t1u2z1+jKl5fp5j+u1IL12frtl7t8ehIPl1Rr1pLd2l90+kZ7xe4jmr7oW+WWVHu3lVbXatrCzVq4Idtnm79Xl5628Bv9aeV+zVi886yfa/GWPE18Z4N3Hl5RhVP/3JbfIXtk27zOSGVlpYYOHaoHH3xQd9xxx2n3379/v2688UZNnjxZ7733nlavXq2f/OQn6tatW6uOR+s07Rlpfj7Hqr1FWtWo9yHaHqKIsGC53B71i4/WfSN66r/+/q3PMTvzW56wujO/XDvzy1VeU6fJo3vroXc26IZBCfrtnUPlNgz95oudurJfd11/frwk6Y3l36nK5daUK/voTyv3aWSfrqqt8+jNFSe+TVc46/R/G3N8vmFnHv+H/cYhCRqR1lX3j0yVzWbzKcuxSpfmrtovw6j/R2trbpmSOofr8QWbvfus3FNf9xc+267ecVF6/tZB6hkbqd98sVP/2JqvfUWVSouL1BMLv2m2vt8eqg8bj/51k+whQXrqB/11ca9YzczcrW8PleqRv2zS0qeuavHvFaiKKpzK3F6gHw7rofDQYO/2wyXV6hwZqsiwEFU66zQzc7ckafK7G5VbUq2f33S+unYK0xMLN/sE4PyyGvXoHCGX26OjlS5FhoYoOjxEQUG2Jq99uKRancJDtGRHgff9tDmnRIdLarzn7uvnrldsVFi71nn6oi36ePNhzZtwsYb36qJPNh/WO2sO6JW7L1RwkE2v/nuvthwPwNXHA3ZNrUdvrdovSdqVX65yZ51+fccQvbcuW//eWai/bWx+GPTP6w5KkmZm7tZj1/aVJO0trFC1y60hyQ7lHK1SbFSYouz1/yQXltdoU3aJyqpr1bVTmLpG2RVlD1ZaXCcFN/M3rC+bW6HBQVq9t0gffF1fjrHDeshms+nO19fIJptW/NfVSnCEy+Mx9PI/d8keEqT1+4/q4l6xqql16z/SkxUcZFPvbp0kSf+3MUfvf5Wt3901VM5aj2Yt2a1th+tDzb7jIaO61q1nFm2RJH2bW6rS6lo9f8v5env1AX36zWF9svmwwkOD1T8hWr8/vt6RYRg+n9+f/f0bFZQ5Ve1ya/qNA9UlMkzvrTuoRZtytWhTrsYO66F9Ryp122urdWFyZy18+NImn//2VFTh1EPvbNAVfeP0sx8MkCT9Y0uePtuSp/UH6sPxF9vyJUlVrjodq6pVtatOpdV1SukSoZiIUNlDgpoto2EYqnDWKTo8VE/+7RtV17oVFGTTczedr2c/2qKVe4r02LV9Ne36fuesfoHIZpzFjEabzaYPP/xQY8eObXGfp59+Wp988ol27Njh3TZlyhR98803Wrt2batep6ysTA6HQ6WlpYqJiTnT4lra19nHdPvsNd6fY6PCdLTy+115NTw0SDW19Yk+JjxE0eGh3m86Nw1JVFlNrTcMnK0fje6tAQnR+vfOQgUH2RTXya65xxsJfxt/aap6dInQ8l1H1D8hWqldI/WHf+3RsWa+hffpFqULkjvrgmSHhvRwqHe3TnJEhCo4yKaPN+dq6c5CPXZtXx2rcumjTYd11/AU9Y3vpCPlTiV3iWi3f5DHvrZam3NKJEkXJDt0zyU9Vecx9IuPt+r8xBj9R3qyfvVp056xllySFqutuaWqaqb3bWTvrjo/KUYj0mJ1rMql//fhVoUcP4eNvxk39v9uHKAl2ws1qEeMRvWJ09825mjlniPe95vNJiV3iVBqbJTO695JfeM76bxunZQWFyVHZKjsIfUBa/nuI9qcXaIHRqXqwhcyvc9vs9X3GkpSdHiIT7Bqb3Gd7Jo+ZoCe/2SbKpx1+slVffTmin26KLWLnr1xoB796yZln2aYsV98J13cK1ZDejh0QXJnudweTXxng0KDg9QzNtLbYJ7s8Wv7atXeIh0pd57yNdLiotQvvpO+3FZwVnU9WXyMXb+780L98tNt6hoVpieu76f//my7N+BI9eciyREhZ51bRRX1/4bZQ4J8lij46KeXeUPXQ5elaWSfrlq1p0j7jlSowulWaLBNnSPDlOgIV0pshFK6RKp7dLg6hYd4w9yqPUXadrhU947oqeIKlzYePKbrBnbXkh2F2ltY4f0ydH5ijK7s301zljUdfrz8vDifL3cnS3SEq3e3KF3cK1YDEqKVEhup15fv06ffHNZ/pCefcg7f9DED1KdbJ63dV6z+8dGKtAfr3TUHNKpPnO6+JEUrdxdpZ365SqpdCg0KkiMyVHGdwpTgiFBylwj16ByhLpFhCgs5/QBIpbNOocFBrdq3rVrbfp/zMDJ69GgNGzZMr7zyinfbhx9+qLvuuktVVVUKDQ1tcozT6ZTTeaIbvaysTCkpKYSRU9hw4KjufP1EuAsLDpKrA3b1AQDOzOv/ma4bBie063O2Noyc8wms+fn5io+P99kWHx+vuro6FRU1nyhnzJghh8PhfaSkpJzrYpreycM0BBEAQFuEtDAE+L289vfxIid3JTd0xrTUxTx9+nRNmzbN+3NDzwhadvIEVgQWR0Sorh3YXQkx4arzGCosq9H+okp9m1sqTl3bRYUF6/K+cUp0REiqnyN0uKRa+4oqO9zVHR1ZWlyUzwRZe0iQYiJC5arzqLT61JOTzahv907aU3ji9h5hwUHq2ilMHsPQsapauc5ite2xFybp2oHd26OYZ+Sch5GEhATl5+f7bCssLFRISIi6du3a7DF2u112u/1cF81SPGfRETI02aE/Txqh7OIq3fzHVWf8PJMuT5Mk7wQ/6cTclaEpnfXMDQO0fv9R/X7JbiU6wuWICG0yOfaxa/vqu8IKfd7oqoSWrHnmGoWFBKna5VZRhVNfZ5d4r/h54rp+io+xeyfWncqItFg9ek1f/efcr9pSXUnShSmdFRkWrDXfFatbtF0TRvXShFG9VFjuVGpspLKPViku2q5O9tZ91OrcHhWUO7XvSIU8hnRZn64qqa7VltxSjUiLlbPWo82HSnRBD4e6dmrfz8iOvDL9Y0ueXl+xT646j67oG6eHR/fRLz7eql/dNkh/+NcebTx4zCc8PXbNefrDv5u/QmTshUm6qn93dY+xy1nr0e6Cch06Vq3V3xVp35FKBdmk9yddqgRHuH40f6PPP7INenSO0L0jemp0324akuxQhbNOYW0c2/Z4DJVU1yr3WLXqPB5dmNJZ5c467ThcpinvZelYVa2mXd9P1wzo7n3/d4+2q7AVoaZbtF03Dk7Qu2sPtro8d1yUrB+N7q0vtubroct7KXN7gYoqnJp8RW99+m2elu86op9c3Ue9ukZ55zeU19SqpKpWheU1yjp4TAeKq7R81xHvHJvX/zNdQ1McenzBZq3f33S+SK+ukfrJVefpwp6d5arztOpzft+InrpreIpue221JOnaAd31r1Zcyt892q6r+ndrMpn388cu18x/7pYjMlSPXH2epi7crAdG9lLOsSrNWfadz5yQ1K6ROljcdE5Lt2i7bhqSqFuGJik9tYuk+gmkEaHBrZo/ZRiGqmvdKixzqtbt0XndO6nOY2hvYYX6xUfrSLlTXaJClV9ao7dXH9A7aw5Ikna9eINKqmo14n//5fN8XaPCNHPchRqUFCNHRKjcHkN1HkMHiipVcPwLx9fZx7Qzv1z7jlRq7IVJmnX3MC1Yn62ff7RVbsPw+TxFhQXrxR8OVs/YSKWnxspZ55Y9JFg1tW7vhNhql1thIUEtTmQ+Wa3bo7LqWpVU1yqta1Szk8gDwfcygfXTTz/V9u0nJr/9+Mc/1ubNm5nA2o5W7D7iXROkNf577GD16hqp+WsP6hc3n6+U2EhJ9dfQX/7rpW1+/RuHJGjG7RcoMixYa78r1mMLNun2Ycn6j/RkzV62V0/fMEApsZEyDEOffZunC1M6q9bt0fy1B3XX8BT96tNtumt4iu5IT9by3Uf0wPG63DuipxJiwrV+/1Gt/q5IhiFd0itWY4Yk6MHL0pqU44OsQ4oMC9aYIYly1XmU8fvlqnUbmn3fReoVF6XvjlTI7TH016+ytea7YuWX1XjHSaf8OUtfbMvXz37QX//clq9vjl85Yw8JUmRYcJMJqF0iQ7XpFxkqrnBq4cYc3XNxT3Vp5ys+/OVIuVPR4SE+V9ZUOOtUUuXyvj9Su0Zq+c+uVnZxlf62MUevLt2rCaN6aWBitFK6RGrUeXEtPr9hGKp1Gz6hYld+uQ4WV+pHf86SJD16zXn60ejeig5vOq+svWzKPqasg8d074ieigwL0czM3frLV9n6wz0X6rNv8/SXr7J1y9AkRYXVXw3y4aZc5Ryt8r4Xxg1P0Ut3DNH2vDL9dX223luX3eJrXd2/m6bfOFA9YyN9/q5nq9rlVkTYiec7dKxKheVO74T2x6/tq59efZ73b20YhmYv+072kCD9YFCC4jrZtbugXGEhQfpyW74Kymr0TU6p3hifrpTYSC3ckK2PNx/WL28dpIUbcjR31X7dc0lPSdLAxGgt3JCjvNIa74T5+0b01ItjB2vb4TIt2HDib7LrxRu8E4lP5vEYGv4/S7zPsX/GjTpS4dRX+47q0b9ukiQ9fcMA3XdpT8Wcw/dDYzW1bs3M3K1hKZ01ZkiiJOm5j7bqo825euv+4QoPDVbf+E6KDDuz7/Ruj6GjlS7d/eZafXekvnfnwEs3tVv5A8U5m8BaUVGhvXvrvwkNGzZMM2fO1NVXX63Y2Fj17NlT06dPV25urubPny+p/tLewYMH6+GHH9bkyZO1du1aTZkyRX/9619bfWkvYeT0lu0q1IS3N7R6/38+MVr94qOb/d0f/7VHvzt+Cack3X5RD3WPDm9xMauGRrm9GIahzO0FGtTDoR6dI7zb80qrlVdao4t6dmn1c9XUumUY8vnHukFZTX3X/oCE+vdUaXWtduaVaXivWGUdPKaXv9ypSVf0VnpqF9lDgvR/Gw9p6+FSLfo6V5J098UpeumOC86ytubzzAffasGGHL1w2yDdP7KXpPrGpP6y6KhWf2NrTpWrTqNe+rfKqmu1+PErvOfGH8prarXmu2KN7NPV2wDWf/P1aOnOI/rzugP63x8OUWrXKEnSX9dna/qiLeoaFaaf/aC/nlm0RdPHDNCMf9SvR/HAyFT96rbB30vZPR5Dt7y6SrsLyvXpo5e329+x1u3R9sNlGpgY4w03dW6P6jyGlu8+or98la3/+eFgJXep/3KTXVylh97doIzz4/VfNww45XPPzNytP/xrj24YlKDXx6dLqg/F1/x2mSRpxX9dHRBh/+TLks9W5vYC/fQvX2va9f005co+7fa8geKchZFly5bp6quvbrL9gQce0DvvvKMJEybowIEDWrZsmfd3y5cv1xNPPKFt27YpKSlJTz/9tKZMmdLulenI/r2zQA+9s7HV+2f9/LoWu/lr3R59te+oHBGhWrqrUBMu66UF67P1v8cX+RmUFKP9RZXeyza7RoUp67nrz74SJvF19jG9u+aAnr5hgJIahaWOos7t0a6Ccg1MiDknXb4HiytVXOlqU+gMBHVuj95bd1BDkh1KT41VpbNOUfYQTV+0Rf/aUaC/TL5U53Xv9L2Vp8pVp5KqWtO8R+vcHn25rUCj+nT1CR2HS6rl9hje3lsrqnN7FBJszQXRv5dLe78vhJHTW7K9QJPmtz6M7J9xY5vSfc7RKt3zp3W6JC1WM24fImedR2NfW619Ryr16DXn6cmM/mdSbKBDaO9v04BZtLb9/l6upsG5525FprwkLVbr9x/VFX3j2vwPY0pspFY9fY33Z3tIsBb86FJ9vOmw7ru0Z5vLC3QkBBHg1AgjFtFSB1fj1STvG9FTz4wZoCE9HO3ymt2jwzV5dO92eS4AQMdlzUGqDqhhjbOTL3mMazQvJCYiVBf17KJQi45NAgDMiVbJIhoWPbMHnxxGTkwE+74uiQMAoC0IIxbhDSOhvqe08Qz0mHBG5QAAgYcwYhENYSTspJ6Rvt1PrCXSsB4CAACBhK/KFtEwZ8R+0sqO5yfF6LV7L1KCw35Obg8NAMDZIoxYREs9IxGhwbqyXzd/FAkAgFbhq7JFeDzNzxkJD+UUAwACGy2VRRzPIs32jAAAEMgIIxbhbuFqmva8OygAAOcCYcQijBbmjBBGAACBjjBiEe6GOSMhvuGDOSMAgEBHS2URDXNGQkPoGQEAmAthxCIahmmCT7o5KPehAQAEOloqi2gYpgkK4lblAABzIYxYRMMwTZCNMAIAMBfCiEV4vMM0hBEAgLkQRizC4x2m8XNBAABoI5oui2hY9CzIZlNKbIQkqXc37tILAAh8hBGLaDxnZO4DF+vGIQl6/T/T/VsoAABagbv2WkTDME1wkE394qM1+z6CCADAHOgZsYiGCazMXwUAmA1hxCLcXE0DADApwohFGA1zRlj0DABgMoQRi/CuwErPCADAZAgjFuHxXtrr54IAANBGhBGL8NAzAgAwKcKIRXiYMwIAMCnCiEUwTAMAMCvCiEVwozwAgFkRRizC46n/L8M0AACzIYxYROMb5QEAYCaEEYtgzggAwKwIIxbR+EZ5AACYCWHEIhou7bUxTAMAMBnCiEWcuFGenwsCAEAbEUYswmiYM8IwDQDAZAgjFsGN8gAAZkUYsQjvcvCEEQCAyRBGLOLE1TR+LggAAG1E02URDeuMcDUNAMBsCCMW4T4+TMO9aQAAZkMYsYgTV9P4uSAAALQRTZdFeLg3DQDApM4ojMyePVtpaWkKDw9Xenq6Vq5cecr9X3vtNQ0cOFARERHq37+/5s+ff0aFRcu4tBcAYFYhbT1g4cKFmjp1qmbPnq3LLrtMb7zxhsaMGaPt27erZ8+eTfafM2eOpk+frj/96U+6+OKLtX79ek2ePFldunTRLbfc0i6VwIlLe7k3DQDAbNrcMzJz5kxNnDhRkyZN0sCBAzVr1iylpKRozpw5ze7/5z//WQ8//LDGjRun3r176+6779bEiRP161//+qwLjxM8Hu7aCwAwpzaFEZfLpaysLGVkZPhsz8jI0Jo1a5o9xul0Kjw83GdbRESE1q9fr9ra2haPKSsr83ng1JgzAgAwqzaFkaKiIrndbsXHx/tsj4+PV35+frPH/OAHP9Bbb72lrKwsGYahjRs3at68eaqtrVVRUVGzx8yYMUMOh8P7SElJaUsxOyQ3K7ACAEzqjCawnrywlmEYLS629dxzz2nMmDG69NJLFRoaqttuu00TJkyQJAUHBzd7zPTp01VaWup95OTknEkxO5SGS3uZMwIAMJs2hZG4uDgFBwc36QUpLCxs0lvSICIiQvPmzVNVVZUOHDig7Oxs9erVS9HR0YqLi2v2GLvdrpiYGJ8HTq3haho6RgAAZtOmMBIWFqb09HRlZmb6bM/MzNSoUaNOeWxoaKiSk5MVHBysBQsW6Oabb1YQK3S1G66mAQCYVZsv7Z02bZrGjx+v4cOHa+TIkXrzzTeVnZ2tKVOmSKofYsnNzfWuJbJ7926tX79eI0aM0LFjxzRz5kxt3bpV7777bvvWpIPzsM4IAMCk2hxGxo0bp+LiYr3wwgvKy8vT4MGDtXjxYqWmpkqS8vLylJ2d7d3f7Xbrd7/7nXbt2qXQ0FBdffXVWrNmjXr16tVulUDjG+X5uSAAALSRzWiY+RjAysrK5HA4VFpayvyRFlzzu2Xad6RSC390qUb07urv4gAA0Or2m0kbFtEQKYOYMwIAMBnCiEVwbxoAgFkRRizixAqsfi4IAABtRBixCINLewEAJkUYsQiGaQAAZkUYsQhulAcAMCvCiEV4wwhnFABgMjRdFuFdDp6eEQCAyRBGLOLEjfIIIwAAcyGMWERDGAnhahoAgMkQRiyizuORxKW9AADzIYxYxPEsopBgwggAwFwIIxbh7RlhzggAwGQIIxZgGMaJq2kYpgEAmAxhxAIaJq9KUggLjQAATIaWywLqGoURsggAwGxouiygYfVViZ4RAID50HJZQOOeEeaMAADMhjBiAW43YQQAYF6EEQtwNxqmIYsAAMyGMGIBjZeC5940AACzIYxYQMOckSC6RQAAJkQYsQAPN8kDAJgYYcQCGnpGWAoeAGBGhBELcDfcl4ab5AEATIgwYgHuhjv2MkwDADAhwogFNNyxN4hhGgCACRFGLMBDzwgAwMQIIxZQx5wRAICJEUYswM3VNAAAEyOMWIA3jDBMAwAwIcKIBZxYDp7TCQAwH1ovC2A5eACAmRFGLKDhrr1cTQMAMCPCiAW43fSMAADMizBiAXXcKA8AYGKEEQvwGFxNAwAwL8KIBXDXXgCAmRFGLMDTMEzDCqwAABMijFhAHYueAQBMjDBiAe6Ge9MwTAMAMCHCiAW4j9+1l54RAIAZEUYsoKFnhDkjAAAzIoxYgHc5eIZpAAAmdEZhZPbs2UpLS1N4eLjS09O1cuXKU+7//vvva+jQoYqMjFRiYqIefPBBFRcXn1GB0ZSbRc8AACbW5jCycOFCTZ06Vc8++6w2bdqkK664QmPGjFF2dnaz+69atUr333+/Jk6cqG3btun//u//tGHDBk2aNOmsC496bm6UBwAwsTaHkZkzZ2rixImaNGmSBg4cqFmzZiklJUVz5sxpdv9169apV69eeuyxx5SWlqbLL79cDz/8sDZu3HjWhUc9loMHAJhZm8KIy+VSVlaWMjIyfLZnZGRozZo1zR4zatQoHTp0SIsXL5ZhGCooKNDf//533XTTTS2+jtPpVFlZmc8DLfN41xlhChAAwHza1HoVFRXJ7XYrPj7eZ3t8fLzy8/ObPWbUqFF6//33NW7cOIWFhSkhIUGdO3fWH//4xxZfZ8aMGXI4HN5HSkpKW4rZ4ZxY9MzPBQEA4AycUfNlO+mqDcMwmmxrsH37dj322GP6xS9+oaysLH3xxRfav3+/pkyZ0uLzT58+XaWlpd5HTk7OmRSzwzgxgZU0AgAwn5C27BwXF6fg4OAmvSCFhYVNeksazJgxQ5dddpl+9rOfSZIuuOACRUVF6YorrtCLL76oxMTEJsfY7XbZ7fa2FK1Dc3PXXgCAibXpq3RYWJjS09OVmZnpsz0zM1OjRo1q9piqqioFnfSNPTg4WFJ9jwrOnpt70wAATKzN/frTpk3TW2+9pXnz5mnHjh164oknlJ2d7R12mT59uu6//37v/rfccosWLVqkOXPmaN++fVq9erUee+wxXXLJJUpKSmq/mnRghBEAgJm1aZhGksaNG6fi4mK98MILysvL0+DBg7V48WKlpqZKkvLy8nzWHJkwYYLKy8v16quv6sknn1Tnzp11zTXX6Ne//nX71aKDY9EzAICZ2QwTjJWUlZXJ4XCotLRUMTEx/i5OwPn5R1v03rpsPX5tXz1xfT9/FwcAAEmtb7+5/MICGKYBAJgZYcQCat31YSSUhUYAACZE62UBdW6PJCk0mJ4RAID5EEYsoJYJrAAAEyOMWEBDz0gIwzQAABOi9bKAhjkjYYQRAIAJ0XpZQK23Z4RhGgCA+RBGLKDueM8IwzQAADOi9bKAOs/xq2mYwAoAMCHCiAW4WGcEAGBitF4WUMecEQCAiRFGLKCOnhEAgInRellA7fE5Iyx6BgAwI8KIBTRc2hsawukEAJgPrZcFeIdpgjidAADzofWygFrvOiMM0wAAzIcwYgHedUYIIwAAEyKMWEBtXUMY4XQCAMyH1ssCaj0sBw8AMC9aLwtoWPSM5eABAGZEGDE5t8fQ8Y4RekYAAKZE62VyDWuMSExgBQCYE2HE5OoaukXEBFYAgDnReplcXaOeEZaDBwCYEWHE5BoWPJOkYMIIAMCECCMm1zBnJCw4SDYbYQQAYD6EEZOrYyl4AIDJEUZMrvb4UvDMFwEAmBVhxOS8d+zlShoAgEnRgplcw5wRwggAwKxowUyuIYwwZwQAYFaEEZNrWPSMnhEAgFnRgpmct2eECawAAJMijJjciUt7OZUAAHOiBTM5Z119z4g9hFMJADAnWjCTcx0PI2GEEQCASdGCmZzL7ZZEzwgAwLxowUzOWcswDQDA3GjBTM7lZpgGAGButGAmd6JnJNjPJQEA4MwQRkzO2zPCpb0AAJOiBTM5J1fTAABMjhbM5Jx1XE0DADA3WjCTY50RAIDZ0YKZHGEEAGB2Z9SCzZ49W2lpaQoPD1d6erpWrlzZ4r4TJkyQzWZr8hg0aNAZFxonnFgOnqtpAADm1OYwsnDhQk2dOlXPPvusNm3apCuuuEJjxoxRdnZ2s/u/8sorysvL8z5ycnIUGxurO++886wLD3pGAADm1+YWbObMmZo4caImTZqkgQMHatasWUpJSdGcOXOa3d/hcCghIcH72Lhxo44dO6YHH3ywxddwOp0qKyvzeaB5TGAFAJhdm1owl8ulrKwsZWRk+GzPyMjQmjVrWvUcc+fO1XXXXafU1NQW95kxY4YcDof3kZKS0pZidij0jAAAzK5NLVhRUZHcbrfi4+N9tsfHxys/P/+0x+fl5ekf//iHJk2adMr9pk+frtLSUu8jJyenLcXsUBoWPaNnBABgViFncpDNZvP52TCMJtua884776hz584aO3bsKfez2+2y2+1nUrQOhxvlAQDMrk0tWFxcnIKDg5v0ghQWFjbpLTmZYRiaN2+exo8fr7CwsLaXFM3iRnkAALNrUwsWFham9PR0ZWZm+mzPzMzUqFGjTnns8uXLtXfvXk2cOLHtpUSLGnpGwoK5tBcAYE5tHqaZNm2axo8fr+HDh2vkyJF68803lZ2drSlTpkiqn++Rm5ur+fPn+xw3d+5cjRgxQoMHD26fkkNSozkjofSMAADMqc1hZNy4cSouLtYLL7ygvLw8DR48WIsXL/ZeHZOXl9dkzZHS0lJ98MEHeuWVV9qn1PDyXk3DXXsBACZlMwzD8HchTqesrEwOh0OlpaWKiYnxd3ECyvAXM1VU4dIXU6/QgAT+NgCAwNHa9puv0ybnpGcEAGBytGAm5720N5QJrAAAcyKMmFid2+OdwBpJGAEAmBRhxMRqjg/RSFJEGGEEAGBOhBETq3bV3yTPZmMFVgCAedGCmVhNbX0YiQgNbtVy/AAABCLCiIlVNwojAACYFWHExKqOD9OEE0YAACZGGDGxhjkjTF4FAJgZYcTEahimAQBYAGHExLxzRugZAQCYGGHExLzDNPSMAABMjDBiYlxNAwCwAsKIiTGBFQBgBYQRE2voGeHSXgCAmRFGTKwhjETSMwIAMDHCiIkxgRUAYAWEEROr4dJeAIAFEEZMrJKeEQCABRBGTKyiplaS1Ck8xM8lAQDgzBFGTKzCWSdJirYTRgAA5kUYMbEKZ/0wTRRhBABgYoQRE6twMkwDADA/woiJVdQwTAMAMD/CiIlVMkwDALAAwohJOevccrk9khimAQCYG2HEpBqGaCQpKowwAgAwL8KISTUM0USGBSs4yObn0gAAcOYIIyZV3nAlDfNFAAAmRxgxqYZhGuaLAADMjjBiUpWu42GEnhEAgMkRRkyqtLp+mMYREernkgAAcHYIIyZVUkUYAQBYA2HEpBrCSOdIwggAwNwIIybVMEzTOSLMzyUBAODsEEZMqqTKJYlhGgCA+RFGTKqkYQIrwzQAAJMjjJiUd84IPSMAAJMjjJiUd85IJHNGAADmRhgxqYY5I1xNAwAwO8KICbk9RqOraQgjAABzI4yY0LEqlzxG/f93iWKYBgBgboQREyqqcEqSukSGKjSYUwgAMDdaMhMqKq+fLxLXye7nkgAAcPbOKIzMnj1baWlpCg8PV3p6ulauXHnK/Z1Op5599lmlpqbKbrerT58+mjdv3hkVGCd6RggjAAAraPP95xcuXKipU6dq9uzZuuyyy/TGG29ozJgx2r59u3r27NnsMXfddZcKCgo0d+5cnXfeeSosLFRdXd1ZF76j8oaRaMIIAMD82hxGZs6cqYkTJ2rSpEmSpFmzZunLL7/UnDlzNGPGjCb7f/HFF1q+fLn27dun2NhYSVKvXr3OrtQdXFFFwzANk1cBAObXpmEal8ulrKwsZWRk+GzPyMjQmjVrmj3mk08+0fDhw/Wb3/xGPXr0UL9+/fTUU0+purq6xddxOp0qKyvzeeAEhmkAAFbSpp6RoqIiud1uxcfH+2yPj49Xfn5+s8fs27dPq1atUnh4uD788EMVFRXpJz/5iY4ePdrivJEZM2boV7/6VVuK1qEUlNVIkrozTAMAsIAzmsBqs9l8fjYMo8m2Bh6PRzabTe+//74uueQS3XjjjZo5c6beeeedFntHpk+frtLSUu8jJyfnTIppWYdL6v9uSZ0j/FwSAADOXpt6RuLi4hQcHNykF6SwsLBJb0mDxMRE9ejRQw6Hw7tt4MCBMgxDhw4dUt++fZscY7fbZbfzrb85hmEor7S+ZyTREe7n0gAAcPba1DMSFham9PR0ZWZm+mzPzMzUqFGjmj3msssu0+HDh1VRUeHdtnv3bgUFBSk5OfkMityxlVXXqcrlliQlOugZAQCYX5uHaaZNm6a33npL8+bN044dO/TEE08oOztbU6ZMkVQ/xHL//fd797/33nvVtWtXPfjgg9q+fbtWrFihn/3sZ3rooYcUEUFj2laHS+uHaLpEhioiLNjPpQEA4Oy1+dLecePGqbi4WC+88ILy8vI0ePBgLV68WKmpqZKkvLw8ZWdne/fv1KmTMjMz9eijj2r48OHq2rWr7rrrLr344ovtV4sOJO94GKFXBABgFTbDMAx/F+J0ysrK5HA4VFpaqpiYGH8Xx6/eW3dQP/9oq64b2F1vPXCxv4sDAECLWtt+c28ak6FnBABgNYQRk8k+Wh9GkrsQRgAA1kAYMZmDxZWSpF5xUX4uCQAA7YMwYiKGYWh/0fEw0pUwAgCwBsKIiRyrqlV5Tf3djlO7Rvq5NAAAtA/CiIk09IokOsIVHsoaIwAAayCMmIh3vghDNAAACyGMmMiBhvkicQzRAACsgzBiIvuLqyTRMwIAsBbCiInsKSiXJPXp1snPJQEAoP0QRkyi1u3RviP1wzT9E6L9XBoAANoPYcQkDhZXyuX2KCosWD06s/oqAMA6CCMmsSu/QpLUNz5aQUE2P5cGAID2QxgxiV3H54v0j2eIBgBgLYQRk9idXx9G+jFfBABgMYQRk6BnBABgVYQRE6h2ub2rr/ZL4LJeAIC1EEZMYHtemTyG1C3aru7R4f4uDgAA7YowYgJbDpVIkob0cPi3IAAAnAOEERPYklsmiTACALAmwogJbMktkUQYAQBYE2EkwFW56rS3sH7BsyHJhBEAgPUQRgLc9sP1k1e7R9sVH8PkVQCA9RBGAtyW3FJJDNEAAKyLMBLgvskpkSQNJowAACyKMBLgNh48Jkka3quLn0sCAMC5QRgJYHml1Tp0rFpBNmlYT8IIAMCaCCMBbOOB+l6R85Ni1Mke4ufSAABwbhBGAtjGA0clScNTY/1cEgAAzh3CSADbcLxn5OJehBEAgHURRgLUsUqXduTXLwPP5FUAgJURRgLU6u+KZBhSv/hOLHYGALA0wkiAWrH7iCRpdN9ufi4JAADnFmEkABmGoZV7iiRJo/sRRgAA1kYYCUA78sqVV1oje0iQLklj8ioAwNoIIwFo8ZY8SdJV/bspPDTYz6UBAODcIowEGMMwvGHkxiGJfi4NAADnHmEkwGw7XKZ9RZUKCwnStQPj/V0cAADOOcJIgPnr+mxJ0vUD41kCHgDQIRBGAkiFs04fbcqVJN13aU8/lwYAgO8HYSSALFifrUqXW73jojSyd1d/FwcAgO8FYSRAVLnq9Pry7yRJk0f3ls1m83OJAAD4fhBGAsRbK/erqMKllNgI/Ud6sr+LAwDA94YwEgD2HanQq0v3SpKeyuiv0GBOCwCg4zijVm/27NlKS0tTeHi40tPTtXLlyhb3XbZsmWw2W5PHzp07z7jQVlJT69bjCzbLVefR6H7ddOvQJH8XCQCA71Wbw8jChQs1depUPfvss9q0aZOuuOIKjRkzRtnZ2ac8bteuXcrLy/M++vbte8aFtgqPx9D0RVu0JbdUsVFhmnH7EOaKAAA6nDaHkZkzZ2rixImaNGmSBg4cqFmzZiklJUVz5sw55XHdu3dXQkKC9xEc3LGXOfd4DP384636cFOugmzSq/cMU4/OEf4uFgAA37s2hRGXy6WsrCxlZGT4bM/IyNCaNWtOeeywYcOUmJioa6+9VkuXLj3lvk6nU2VlZT4PKymvqdWP/pylv3yVrSCb9Lu7hmrUeXH+LhYAAH7RpjBSVFQkt9ut+HjfZcrj4+OVn5/f7DGJiYl688039cEHH2jRokXq37+/rr32Wq1YsaLF15kxY4YcDof3kZKS0pZiBrQth0r1w9lrtGRHgcJCgvT7cRfqh8O4egYA0HGd0XrjJ89rMAyjxbkO/fv3V//+/b0/jxw5Ujk5Ofrtb3+r0aNHN3vM9OnTNW3aNO/PZWVlpg8krjqPXv33Hr227Du5PYa6R9v15v3DdWFKZ38XDQAAv2pTGImLi1NwcHCTXpDCwsImvSWncumll+q9995r8fd2u112u70tRQto3x4q0dMfbNGOvPrhppsuSNQLtw5S107WqSMAAGeqTcM0YWFhSk9PV2Zmps/2zMxMjRo1qtXPs2nTJiUmJrblpU2p0lmn//5su8a+tlo78srUJTJUr947TK/dexFBBACA49o8TDNt2jSNHz9ew4cP18iRI/Xmm28qOztbU6ZMkVQ/xJKbm6v58+dLkmbNmqVevXpp0KBBcrlceu+99/TBBx/ogw8+aN+aBJilOwv184+2KrekWpJ024VJeu7m8xVHCAEAwEebw8i4ceNUXFysF154QXl5eRo8eLAWL16s1NRUSVJeXp7PmiMul0tPPfWUcnNzFRERoUGDBunzzz/XjTfe2H61CCCF5TV64dPt+uzbPElScpcIvTh2sK7q393PJQMAIDDZDMMw/F2I0ykrK5PD4VBpaaliYmL8XZxmuT2GFm7I0Uv/2KGymjoF2aRJV/TW1Ov6KjLsjOYJAwBgaq1tv2kl28G6fcV64dPt2n58gurgHjF66fYLNLiHw88lAwAg8BFGzsKWQ6X6w7/3KHN7gSQpOjxEj1/bVxNG9VIIN7sDAKBVCCNtVOf2aPnuI3p37UGt2H1EkhRkk+65pKemXd+Pq2QAAGgjwkgreDyGvjlUon9uL9CHX+cqv6xGUn0IuXVokn569XnqGx/t51ICAGBOhJEWVLvcWrW3SEu2F+hfOwtVVOH0/i42Kkw/HNZD949MVWrXKD+WEgAA8yOMNFJU4dQ/txVoyY4Crd5bJGedx/u7aHuIruzfTWMGJ+q687vLHtKx7zoMAEB7IYxIWvtdsd5dc0BLdhSoznPiSufkLhG6bmC8rhsYr0vSYhUWwqRUAADaW4cOI1/tK9bvl+zWun1HvdsuSHboB4MSdN3AePWL79TiDQABAED76LBhxDAMvfzlLm08eExhwUG66+Jk/eelqRqQEJiLqgEAYFUdNozYbDZNy+inz7/N00+vPk9JnSP8XSQAADqkDhtGJGlUnziN6hPn72IAANChMSMTAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4FWEEAAD4lSnu2msYhiSprKzMzyUBAACt1dBuN7TjLTFFGCkvL5ckpaSk+LkkAACgrcrLy+VwOFr8vc04XVwJAB6PR4cPH1Z0dLRsNlu7PW9ZWZlSUlKUk5OjmJiYdnveQGL1OlI/87N6Ha1eP8n6daR+Z84wDJWXlyspKUlBQS3PDDFFz0hQUJCSk5PP2fPHxMRY8g3WmNXrSP3Mz+p1tHr9JOvXkfqdmVP1iDRgAisAAPArwggAAPCrDh1G7Ha7nn/+edntdn8X5Zyxeh2pn/lZvY5Wr59k/TpSv3PPFBNYAQCAdXXonhEAAOB/hBEAAOBXhBEAAOBXhBEAAOBXhBEAAOBXHTqMzJ49W2lpaQoPD1d6erpWrlzp7yKd1owZM3TxxRcrOjpa3bt319ixY7Vr1y6ffSZMmCCbzebzuPTSS332cTqdevTRRxUXF6eoqCjdeuutOnTo0PdZlRb98pe/bFL+hIQE7+8Nw9Avf/lLJSUlKSIiQldddZW2bdvm8xyBXL9evXo1qZ/NZtNPf/pTSeY8fytWrNAtt9yipKQk2Ww2ffTRRz6/b69zduzYMY0fP14Oh0MOh0Pjx49XSUnJOa7dqetXW1urp59+WkOGDFFUVJSSkpJ0//336/Dhwz7PcdVVVzU5r3fffXfA109qv/ekv+onnb6OzX0mbTabXn75Ze8+gXwOW9M2BPLnsMOGkYULF2rq1Kl69tlntWnTJl1xxRUaM2aMsrOz/V20U1q+fLl++tOfat26dcrMzFRdXZ0yMjJUWVnps98NN9ygvLw872Px4sU+v586dao+/PBDLViwQKtWrVJFRYVuvvlmud3u77M6LRo0aJBP+bds2eL93W9+8xvNnDlTr776qjZs2KCEhARdf/313hsqSoFdvw0bNvjULTMzU5J05513evcx2/mrrKzU0KFD9eqrrzb7+/Y6Z/fee682b96sL774Ql988YU2b96s8ePH+7V+VVVV+vrrr/Xcc8/p66+/1qJFi7R7927deuutTfadPHmyz3l94403fH4fiPVr0B7vSX/VTzp9HRvXLS8vT/PmzZPNZtMdd9zhs1+gnsPWtA0B/Tk0OqhLLrnEmDJlis+2AQMGGM8884yfSnRmCgsLDUnG8uXLvdseeOAB47bbbmvxmJKSEiM0NNRYsGCBd1tubq4RFBRkfPHFF+eyuK3y/PPPG0OHDm32dx6Px0hISDBeeukl77aamhrD4XAYr7/+umEYgV+/kz3++ONGnz59DI/HYxiG+c+fJOPDDz/0/txe52z79u2GJGPdunXefdauXWtIMnbu3HmOa3XCyfVrzvr16w1JxsGDB73brrzySuPxxx9v8ZhArl97vCcDpX6G0bpzeNtttxnXXHONzzaznEPDaNo2BPrnsEP2jLhcLmVlZSkjI8Nne0ZGhtasWeOnUp2Z0tJSSVJsbKzP9mXLlql79+7q16+fJk+erMLCQu/vsrKyVFtb61P/pKQkDR48OGDqv2fPHiUlJSktLU1333239u3bJ0nav3+/8vPzfcput9t15ZVXestuhvo1cLlceu+99/TQQw/53JHa7OevsfY6Z2vXrpXD4dCIESO8+1x66aVyOBwBV+/S0lLZbDZ17tzZZ/v777+vuLg4DRo0SE899ZTPN9JAr9/ZvicDvX6NFRQU6PPPP9fEiROb/M4s5/DktiHQP4emuGtveysqKpLb7VZ8fLzP9vj4eOXn5/upVG1nGIamTZumyy+/XIMHD/ZuHzNmjO68806lpqZq//79eu6553TNNdcoKytLdrtd+fn5CgsLU5cuXXyeL1DqP2LECM2fP1/9+vVTQUGBXnzxRY0aNUrbtm3zlq+5c3fw4EFJCvj6NfbRRx+ppKREEyZM8G4z+/k7WXuds/z8fHXv3r3J83fv3j2g6l1TU6NnnnlG9957r88dUO+77z6lpaUpISFBW7du1fTp0/XNN994h+kCuX7t8Z4M5Pqd7N1331V0dLRuv/12n+1mOYfNtQ2B/jnskGGkQeNvolL9CTx5WyB75JFH9O2332rVqlU+28eNG+f9/8GDB2v48OFKTU3V559/3uTD1Vig1H/MmDHe/x8yZIhGjhypPn366N133/VOmjuTcxco9Wts7ty5GjNmjJKSkrzbzH7+WtIe56y5/QOp3rW1tbr77rvl8Xg0e/Zsn99NnjzZ+/+DBw9W3759NXz4cH399de66KKLJAVu/drrPRmo9TvZvHnzdN999yk8PNxnu1nOYUttgxS4n8MOOUwTFxen4ODgJimusLCwSWoMVI8++qg++eQTLV26VMnJyafcNzExUampqdqzZ48kKSEhQS6XS8eOHfPZL1DrHxUVpSFDhmjPnj3eq2pOde7MUr+DBw9qyZIlmjRp0in3M/v5a69zlpCQoIKCgibPf+TIkYCod21tre666y7t379fmZmZPr0izbnooosUGhrqc14DuX6Nncl70iz1W7lypXbt2nXaz6UUmOewpbYh0D+HHTKMhIWFKT093du11iAzM1OjRo3yU6laxzAMPfLII1q0aJH+/e9/Ky0t7bTHFBcXKycnR4mJiZKk9PR0hYaG+tQ/Ly9PW7duDcj6O51O7dixQ4mJid4u0sZld7lcWr58ubfsZqnf22+/re7du+umm2465X5mP3/tdc5Gjhyp0tJSrV+/3rvPV199pdLSUr/XuyGI7NmzR0uWLFHXrl1Pe8y2bdtUW1vrPa+BXL+Tncl70iz1mzt3rtLT0zV06NDT7htI5/B0bUPAfw7PeOqryS1YsMAIDQ015s6da2zfvt2YOnWqERUVZRw4cMDfRTulH//4x4bD4TCWLVtm5OXleR9VVVWGYRhGeXm58eSTTxpr1qwx9u/fbyxdutQYOXKk0aNHD6OsrMz7PFOmTDGSk5ONJUuWGF9//bVxzTXXGEOHDjXq6ur8VTWvJ5980li2bJmxb98+Y926dcbNN99sREdHe8/NSy+9ZDgcDmPRokXGli1bjHvuucdITEw0Tf0MwzDcbrfRs2dP4+mnn/bZbtbzV15ebmzatMnYtGmTIcmYOXOmsWnTJu/VJO11zm644QbjggsuMNauXWusXbvWGDJkiHHzzTf7tX61tbXGrbfeaiQnJxubN2/2+Vw6nU7DMAxj7969xq9+9Stjw4YNxv79+43PP//cGDBggDFs2LCAr197vif9Vb/T1bFBaWmpERkZacyZM6fJ8YF+Dk/XNhhGYH8OO2wYMQzDeO2114zU1FQjLCzMuOiii3wujw1Ukpp9vP3224ZhGEZVVZWRkZFhdOvWzQgNDTV69uxpPPDAA0Z2drbP81RXVxuPPPKIERsba0RERBg333xzk338Zdy4cUZiYqIRGhpqJCUlGbfffruxbds27+89Ho/x/PPPGwkJCYbdbjdGjx5tbNmyxec5Arl+hmEYX375pSHJ2LVrl892s56/pUuXNvu+fOCBBwzDaL9zVlxcbNx3331GdHS0ER0dbdx3333GsWPH/Fq//fv3t/i5XLp0qWEYhpGdnW2MHj3aiI2NNcLCwow+ffoYjz32mFFcXBzw9WvP96S/6ne6OjZ44403jIiICKOkpKTJ8YF+Dk/XNhhGYH8ObccrAQAA4Bcdcs4IAAAIHIQRAADgV4QRAADgV4QRAADgV4QRAADgV4QRAADgV4QRAADgV4QRAADgV4QRAADgV4QRAADgV4QRAADgV/8fF1HrZRmQZfAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_qubits = 8\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 2001\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "n = 3\n",
    "N = 2**n\n",
    "\n",
    "loss_graph = []\n",
    "\n",
    "class input_vec_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.n = n\n",
    "        self.N = N\n",
    "\n",
    "        F = torch.zeros((N,N), dtype=torch.complex128)\n",
    "        w = np.exp(-2*np.pi*1j / N)\n",
    "\n",
    "        for k in range(N):\n",
    "            for j in range(N):\n",
    "                F[j][k] = w**(j*k) / np.sqrt(N)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_qubits):\n",
    "            phi = np.random.rand() * 2*np.pi\n",
    "            theta = np.random.rand() * np.pi\n",
    "\n",
    "            input_qubit = torch.tensor([np.sin(theta), np.cos(theta) * np.exp(1j * phi)])\n",
    "            dataset.append(input_qubit)\n",
    "\n",
    "            q = input_qubit\n",
    "            q0 = torch.tensor([1,0], dtype=torch.complex128)\n",
    "\n",
    "            for i in range(n-1):\n",
    "                q = torch.kron(q,q0)\n",
    "            q = q @ F\n",
    "            labels.append(q)\n",
    "            \n",
    "        self.dataset = torch.stack(dataset)\n",
    "        self.labels = torch.stack(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "\n",
    "data_set = input_vec_dataset()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "class HModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HModel, self).__init__()\n",
    "        self.w = Parameter(torch.rand(1, dtype=torch.complex128))\n",
    "      \n",
    "    def forward(self, x):\n",
    "        w = self.w\n",
    "        \n",
    "        F = torch.zeros((N,N), dtype=torch.complex128)\n",
    "        \n",
    "        for k in range(N):\n",
    "            for j in range(N):\n",
    "                F[j][k] = w**(j*k) / np.sqrt(N)\n",
    "            \n",
    "        q=x\n",
    "        \n",
    "        for i in range(n-1):\n",
    "            q0 = torch.tensor([1,0], dtype=torch.complex128)\n",
    "            q = torch.kron(q,q0)\n",
    "            \n",
    "        return q @ F\n",
    "    \n",
    "model = HModel()\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch):\n",
    "\n",
    "    loss = torch.stack([torch.abs(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    fidelity = torch.stack([torch.abs(torch.dot(target_state.conj(), state))**2\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    loss_graph.append(fidelity.item())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, labels in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch)\n",
    "        \n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        print(f'epoch: {epoch}, loss: {loss}')\n",
    "        \n",
    "model.eval()\n",
    "\n",
    "q_test = torch.tensor([1,0], dtype=torch.complex128)\n",
    "\n",
    "q_out = model(q_test)\n",
    "\n",
    "print(q_out)\n",
    "\n",
    "x_graph = np.arange(num_epochs * num_qubits / batch_size)\n",
    "plt.plot(x_graph,loss_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9750d76b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 152\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, labels \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m    150\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[0;32m    154\u001b[0m     loss \u001b[38;5;241m=\u001b[39m quantum_infidelity_batched(outputs, labels) \n\u001b[0;32m    156\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[1], line 121\u001b[0m, in \u001b[0;36mHModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    118\u001b[0m QFT_out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m--> 121\u001b[0m     QFT \u001b[38;5;241m=\u001b[39m basis(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m    123\u001b[0m         QFT \u001b[38;5;241m=\u001b[39m QFT \u001b[38;5;241m@\u001b[39m h(j)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'basis' is not defined"
     ]
    }
   ],
   "source": [
    "#NEW\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_qubits = 8\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "num_epochs = 501\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "n = 3\n",
    "N = 2**n\n",
    "\n",
    "loss_graph = []\n",
    "\n",
    "class input_vec_dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.n = n\n",
    "        self.N = N\n",
    "\n",
    "        F = torch.zeros((N,N), dtype=torch.complex128)\n",
    "        w = np.exp(-2*np.pi*1j / N)\n",
    "\n",
    "        for k in range(N):\n",
    "            for j in range(N):\n",
    "                F[j][k] = w**(j*k) / np.sqrt(N)\n",
    "\n",
    "        dataset = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(num_qubits):\n",
    "            phi = np.random.rand() * 2*np.pi\n",
    "            theta = np.random.rand() * np.pi\n",
    "\n",
    "            input_qubit = torch.tensor([np.sin(theta), np.cos(theta) * np.exp(1j * phi)])\n",
    "            dataset.append(input_qubit)\n",
    "\n",
    "            q = input_qubit\n",
    "            q0 = torch.tensor([1,0], dtype=torch.complex128)\n",
    "\n",
    "            for i in range(n-1):\n",
    "                q = torch.kron(q,q0)\n",
    "            q = q @ F\n",
    "            labels.append(q)\n",
    "            \n",
    "        self.dataset = torch.stack(dataset)\n",
    "        self.labels = torch.stack(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx],self.labels[idx]\n",
    "\n",
    "data_set = input_vec_dataset()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "def elements_to_matrix(matrix_entries: list):\n",
    "    return torch.stack([torch.stack([value for value in row]) for row in matrix_entries]).squeeze()\n",
    "\n",
    "def crot(control,target,k):\n",
    "    r_gate = torch.tensor([[1,0],\n",
    "                           [0,np.exp(1j*2*np.pi / (2**k))]], dtype=torch.complex128)\n",
    "    q0 = torch.tensor([1,0], dtype=torch.complex128)\n",
    "    q1 = torch.tensor([0,1], dtype=torch.complex128)\n",
    "    \n",
    "    zeros = torch.outer(q0,q0)\n",
    "    ones = torch.outer(q1,q1)\n",
    "\n",
    "    crot = [[i_gate for _ in range(n)] for _ in range(2)]\n",
    "    \n",
    "    crot[0][control] = zeros\n",
    "    \n",
    "    crot[1][control] = ones\n",
    "    crot[1][target] = r_gate\n",
    "    \n",
    "    a = crot[0][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,crot[0][j+1])\n",
    "\n",
    "    b = crot[1][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        b = torch.kron(b,crot[1][j+1])\n",
    "    return a + b\n",
    "\n",
    "class HModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HModel, self).__init__()\n",
    "        self.θ = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.α = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.β = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "        self.ϕ = Parameter(2 * np.pi * torch.rand(1, dtype=torch.float64))\n",
    "      \n",
    "    def forward(self, x):\n",
    "        θ = self.θ\n",
    "        α = self.α\n",
    "        β = self.β\n",
    "        ϕ = self.ϕ\n",
    "        \n",
    "        U = elements_to_matrix(\n",
    "            [[torch.exp(1j * α) * torch.cos(θ), torch.exp(1j * β) * torch.sin(θ)],\n",
    "             [- torch.exp(-1j * β) * torch.sin(θ), torch.exp(-1j * α) * torch.cos(θ)]])\n",
    "        \n",
    "        QFT_out = []\n",
    "        \n",
    "        for a in batch:\n",
    "            QFT = basis(0,0,0)\n",
    "            for j in range(n):\n",
    "                QFT = QFT @ h(j)\n",
    "                for k in range(n-j-1):\n",
    "                    QFT = QFT @ crot(j,k+j+1,k+2)\n",
    "            QFT_out.append(QFT)\n",
    "        return torch.stack(QFT_out)\n",
    "        \n",
    "    \n",
    "model = HModel()\n",
    "\n",
    "def quantum_infidelity_batched(state_batch, target_state_batch):\n",
    "\n",
    "    loss = torch.stack([torch.abs(1 - torch.abs(torch.dot(target_state.conj(), state))**2)\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    fidelity = torch.stack([torch.abs(torch.dot(target_state.conj(), state))**2\n",
    "                        for state, target_state in zip(state_batch, target_state_batch)]).mean()\n",
    "    \n",
    "    loss_graph.append(fidelity.item())\n",
    "    \n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch, labels in data_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(batch)\n",
    "        \n",
    "        loss = quantum_infidelity_batched(outputs, labels) \n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 500 == 0:\n",
    "        \n",
    "        print(f'epoch: {epoch}, loss: {loss}')\n",
    "        \n",
    "model.eval()\n",
    "\n",
    "q_test = torch.tensor([1,0], dtype=torch.complex128)\n",
    "\n",
    "q_out = model(q_test)\n",
    "\n",
    "print(q_out)\n",
    "\n",
    "x_graph = np.arange(num_epochs * num_qubits / batch_size)\n",
    "plt.plot(x_graph,loss_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0906a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5ad3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = torch.tensor([1,0], dtype=torch.complex128)\n",
    "q1 = torch.tensor([0,1], dtype=torch.complex128)\n",
    "\n",
    "i_gate = torch.tensor([[1,0],\n",
    "                       [0,1]], dtype=torch.complex128)\n",
    "x_gate = torch.tensor([[0,1],\n",
    "                       [1,0]], dtype=torch.complex128)\n",
    "z_gate = torch.tensor([[1,0],\n",
    "                       [0,-1]], dtype=torch.complex128)\n",
    "h_gate = torch.tensor([[1,1],\n",
    "                       [1,-1]] / np.sqrt(2), dtype=torch.complex128)\n",
    "\n",
    "def basis(*args):\n",
    "    basis = []\n",
    "    for j in args:\n",
    "        if type(j) == torch.Tensor:\n",
    "            basis.append(j)\n",
    "        elif j == 0:\n",
    "            basis.append(q0)\n",
    "        elif j == 1:\n",
    "            basis.append(q1)\n",
    "\n",
    "    a = basis[0]\n",
    "    for j in range(len(basis)-1):\n",
    "        a = torch.kron(a,basis[j+1])\n",
    "    global n\n",
    "    n = len(basis)\n",
    "    return a\n",
    "\n",
    "def cnot(control,target):\n",
    "    zeros = torch.outer(q0,q0)\n",
    "    ones = torch.outer(q1,q1)\n",
    "\n",
    "    cnot = [[i_gate for _ in range(n)] for _ in range(2)]\n",
    "    \n",
    "    cnot[0][control] = zeros\n",
    "    \n",
    "    cnot[1][control] = ones\n",
    "    cnot[1][target] = x_gate\n",
    "    \n",
    "    a = cnot[0][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,cnot[0][j+1])\n",
    "\n",
    "    b = cnot[1][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        b = torch.kron(b,cnot[1][j+1])\n",
    "    return a + b\n",
    "\n",
    "def crot(control,target,k):\n",
    "    r_gate = torch.tensor([[1,0],\n",
    "                           [0,np.exp(1j*2*np.pi / (2**k))]], dtype=torch.complex128)\n",
    "\n",
    "    zeros = torch.outer(q0,q0)\n",
    "    ones = torch.outer(q1,q1)\n",
    "\n",
    "    crot = [[i_gate for _ in range(n)] for _ in range(2)]\n",
    "    \n",
    "    crot[0][control] = zeros\n",
    "    \n",
    "    crot[1][control] = ones\n",
    "    crot[1][target] = r_gate\n",
    "    \n",
    "    a = crot[0][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,crot[0][j+1])\n",
    "\n",
    "    b = crot[1][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        b = torch.kron(b,crot[1][j+1])\n",
    "    return a + b\n",
    "\n",
    "def cz(control,target):\n",
    "    zeros = torch.outer(q0,q0)\n",
    "    ones = torch.outer(q1,q1)\n",
    "\n",
    "    cz = [[i_gate for _ in range(n)] for _ in range(2)]\n",
    "    \n",
    "    cz[0][control] = zeros\n",
    "    \n",
    "    cz[1][control] = ones\n",
    "    cz[1][target] = z_gate\n",
    "    \n",
    "    a = cz[0][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,cz[0][j+1])\n",
    "\n",
    "    b = cz[1][0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        b = torch.kron(b,cz[1][j+1])\n",
    "    return a + b\n",
    "\n",
    "def swap(control,target):\n",
    "    return cnot(control,target) @ cnot(target,control) @ cnot(control,target)\n",
    "\n",
    "def x(target):\n",
    "    \n",
    "    x = [i_gate for _ in range(n)]\n",
    "    x[target] = x_gate\n",
    "    \n",
    "    a = x[0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,x[j+1])\n",
    "    return a\n",
    "\n",
    "def z(target):\n",
    "\n",
    "    z = [i_gate for _ in range(n)]\n",
    "    z[target] = z_gate\n",
    "    \n",
    "    a = z[0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,z[j+1])\n",
    "    return a\n",
    "\n",
    "def h(target):\n",
    "\n",
    "    h = [i_gate for _ in range(n)]\n",
    "    h[target] = h_gate\n",
    "    \n",
    "    a = h[0]\n",
    "    \n",
    "    for j in range(n-1):\n",
    "        a = torch.kron(a,h[j+1])\n",
    "    return a\n",
    "\n",
    "def QFT(*args):\n",
    "    QFT = basis(*args)\n",
    "    for j in range(n):\n",
    "        QFT = QFT @ h(j)\n",
    "        for k in range(n-j-1):\n",
    "            QFT = QFT @ crot(j,k+j+1,k+2)\n",
    "    return QFT\n",
    "\n",
    "def GHZ(*args):\n",
    "    GHZ = basis(*args)\n",
    "    GHZ = GHZ @ h(0)\n",
    "    for j in range(n-1):\n",
    "        GHZ = GHZ @ cnot(j,j+1)\n",
    "    return GHZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d306d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000+0.j,  0.5000+0.j,  0.5000+0.j,  0.0000+0.j,  0.5000+0.j,  0.0000+0.j,\n",
       "         0.0000+0.j, -0.5000+0.j], dtype=torch.complex128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis(0,0,0) @ h(0) @ x(2) @ cnot(0,1) @ cnot(0,2) @ h(1) @ cnot(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4423da5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j,\n",
       "        0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j, 0.2500+0.j,\n",
       "        0.2500+0.j, 0.2500+0.j], dtype=torch.complex128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QFT(0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b949bd95",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.LongTensor{[2]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m5\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcomplex128)\n\u001b[1;32m----> 2\u001b[0m a[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      3\u001b[0m a\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.LongTensor{[2]}, size=[]): the number of sizes provided (0) must be greater or equal to the number of dimensions in the tensor (1)"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5, dtype=torch.complex128)\n",
    "a[0] = torch.tensor([1,2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1e3179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "       dtype=torch.complex128)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basis(*args):\n",
    "    basis = []\n",
    "    for j in args:\n",
    "        if type(j) == torch.Tensor:\n",
    "            basis.append(j)\n",
    "        elif j == 0:\n",
    "            basis.append(q0)\n",
    "        elif j == 1:\n",
    "            basis.append(q1)\n",
    "\n",
    "    a = basis[0]\n",
    "    for j in range(len(basis)-1):\n",
    "        a = torch.kron(a,basis[j+1])\n",
    "    global n\n",
    "    n = len(basis)\n",
    "    return a\n",
    "\n",
    "basis(torch.tensor([5,0]),0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a95396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j,\n",
       "        0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], dtype=torch.complex128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ghz = 4\n",
    "\n",
    "def basis(*args):\n",
    "    basis = []\n",
    "    for j in range(n_ghz):\n",
    "        basis.append(q0)\n",
    "    for j in args:\n",
    "        basis[0] = j\n",
    "\n",
    "    a = basis[0]\n",
    "    for j in range(len(basis)-1):\n",
    "        a = torch.kron(a,basis[j+1])\n",
    "    return a\n",
    "        \n",
    "basis(torch.tensor([5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2be836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
